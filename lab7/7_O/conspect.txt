КОНСПЕКТ: ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ
===================================

ОБЩАЯ ИДЕЯ
==========

Что делаем:
Реализуем алгоритм логистической регрессии для классификации (предсказание 0 или 1).

Зачем:
Обычная линейная регрессия даёт числа от -∞ до +∞, а нам нужна вероятность от 0 до 1.
Логистическая регрессия использует сигмоидную функцию, которая "сжимает" любое число в интервал [0, 1].

Как работает:
1. Берём признаки X и метки y (0 или 1)
2. Находим параметры theta, которые минимизируют функцию стоимости
3. Используем найденные theta для предсказаний

Результаты:
- ex2.m: точность 89% на задаче поступления в университет
- ex2_reg.m: точность 83% на задаче классификации микрочипов (с регуляризацией)


ЧТО ТАКОЕ РЕГУЛЯРИЗАЦИЯ? (ОБЪЯСНЕНИЕ С НУЛЯ)
=============================================

ПРОБЛЕМА: ПЕРЕОБУЧЕНИЕ (OVERFITTING)
-------------------------------------

Представь ситуацию:
У тебя есть 10 примеров студентов и их результаты поступления.
Модель пытается найти параметры theta, чтобы предсказать поступление.

БЕЗ РЕГУЛЯРИЗАЦИИ:
Модель может стать слишком сложной и "запомнить" каждый пример.
Она идеально предсказывает те 10 студентов, на которых училась.
НО! На новых студентах работает плохо, потому что подстроилась под шум в данных.

С РЕГУЛЯРИЗАЦИЕЙ:
Модель становится проще, не пытается запомнить каждый пример.
Она находит общие закономерности.
На обучающих данных может быть чуть хуже, но на новых данных работает лучше!

АНАЛОГИЯ:
Представь, что ты учишься водить машину:
- БЕЗ регуляризации: ты запоминаешь каждый поворот на тренировочной трассе,
  но на новой дороге теряешься
- С регуляризацией: ты учишь общие принципы вождения,
  которые работают на любой дороге

КОГДА ВОЗНИКАЕТ ПРОБЛЕМА?
-------------------------

1. Много признаков (features)
   Пример: у тебя 2 признака → модель простая
   Но если признаков 28 (как после mapFeature) → модель может переобучиться

2. Мало данных
   Если примеров меньше, чем признаков, модель легко запомнит данные

3. Сложная модель
   Полиномиальные признаки высокой степени создают очень гибкую модель,
   которая может подстроиться под что угодно

КАК РАБОТАЕТ РЕГУЛЯРИЗАЦИЯ?
----------------------------

ИДЕЯ: Штрафуем модель за большие значения параметров theta.

Почему это помогает?
Если theta большие, модель очень чувствительна к изменениям признаков.
Если theta маленькие, модель более "гладкая" и устойчивая.

ФОРМУЛА:
  J_reg = J_обычная + (lambda/2m) * SUM(theta_j^2)

Где:
- J_обычная - обычная функция стоимости (как в costFunction.m)
- lambda - параметр регуляризации (мы его задаём)
- SUM(theta_j^2) - сумма квадратов всех theta (кроме theta_0)

ЧТО ДЕЛАЕТ LAMBDA?
------------------

lambda = 0:
  Нет регуляризации, модель может переобучиться
  J_reg = J_обычная

lambda маленькое (0.01, 0.1):
  Слабая регуляризация
  Модель чуть проще, но всё ещё может переобучиться

lambda = 1:
  Умеренная регуляризация (хороший баланс)
  Модель достаточно простая, но не слишком

lambda большое (10, 100):
  Сильная регуляризация
  Модель слишком простая (недообучение)
  Все theta стремятся к 0, модель почти не учится

ПОЧЕМУ НЕ РЕГУЛЯРИЗИРУЕМ THETA_0?
----------------------------------

theta_0 - это bias (смещение).
Он отвечает за сдвиг всей функции, а не за влияние конкретного признака.

Если мы заставим theta_0 быть маленьким, это просто сдвинет границу решения,
но не сделает модель проще.

Поэтому штрафуем только theta_1, theta_2, ... (те, что умножаются на признаки).

В КОДЕ:
  theta(2:end) - все theta кроме первого
  theta(2:end)' * theta(2:end) - сумма квадратов theta_j для j >= 1

КАК РЕГУЛЯРИЗАЦИЯ ВЛИЯЕТ НА ГРАДИЕНТ?
--------------------------------------

Обычный градиент:
  grad(j) = (1/m) * X(:,j)' * (h - y)

С регуляризацией:
  grad(1) = обычный градиент (без изменений)
  grad(j) = обычный градиент + (lambda/m) * theta(j)    для j >= 2

Что это значит?
Добавляем к градиенту слагаемое (lambda/m) * theta(j).

Если theta(j) > 0, градиент увеличивается → theta(j) будет уменьшаться.
Если theta(j) < 0, градиент уменьшается → theta(j) будет увеличиваться (к 0).

Итог: все theta (кроме theta_0) стремятся к 0, но не становятся нулями,
потому что есть баланс между минимизацией ошибки и минимизацией theta.

ВИЗУАЛЬНОЕ ПОНИМАНИЕ
--------------------

БЕЗ регуляризации (lambda = 0):
  Граница решения может быть очень извилистой, подстраивается под каждый пример
  Точность на обучающих данных: 100%
  Точность на новых данных: 60% (плохо!)

С регуляризацией (lambda = 1):
  Граница решения более плавная, следует общим закономерностям
  Точность на обучающих данных: 83%
  Точность на новых данных: 80% (лучше!)

С сильной регуляризацией (lambda = 100):
  Граница решения почти прямая, слишком простая
  Точность на обучающих данных: 60%
  Точность на новых данных: 65% (тоже плохо!)

ВЫВОД:
Регуляризация - это баланс между точностью на обучающих данных
и способностью обобщаться на новые данные.

ЗОЛОТОЕ ПРАВИЛО:
Лучше чуть хуже на обучающих данных, но лучше на новых!


ФАЙЛ 1: sigmoid.m
=================

ЧТО ДЕЛАЕТ:
Преобразует любое число z в вероятность от 0 до 1.

КОД:
  function g = sigmoid(z)
  g = 1 ./ (1 + exp(-z));
  end

РАЗБОР ПО СТРОКАМ:

1. function g = sigmoid(z)
   - Объявляем функцию с именем sigmoid
   - Вход: z (может быть число, вектор или матрица)
   - Выход: g (результат применения сигмоиды)

2. g = 1 ./ (1 + exp(-z));
   - exp(-z) - вычисляем e^(-z) для каждого элемента
   - 1 + exp(-z) - прибавляем 1
   - 1 ./ (...) - поэлементное деление (точка перед / важна!)
   - Результат: g = 1 / (1 + e^(-z))

ТЕОРИЯ:

Формула сигмоиды: g(z) = 1 / (1 + e^(-z))

Свойства:
- При z → +∞: g(z) → 1
- При z → -∞: g(z) → 0
- При z = 0: g(z) = 0.5
- Всегда в диапазоне [0, 1]

Почему нужна точка перед делением (./)?
В Octave/Matlab:
- 1 / A - обычное деление (матричное)
- 1 ./ A - поэлементное деление

Если z - вектор [z1, z2, z3], то:
  g = [1/(1+e^(-z1)), 1/(1+e^(-z2)), 1/(1+e^(-z3))]

Без точки будет ошибка или неверный результат!
может

ФАЙЛ 2: costFunction.m
======================

ЧТО ДЕЛАЕТ:
Вычисляет функцию стоимости J и градиент grad для логистической регрессии.
Эти значения нужны оптимизатору fminunc для поиска лучших параметров theta.

КОД:
  function [J, grad] = costFunction(theta, X, y)
  m = length(y);
  
  h = sigmoid(X * theta);
  
  J = -(1/m) * (y' * log(h) + (1 - y)' * log(1 - h));
  
  grad = (1/m) * (X' * (h - y));
  end

РАЗБОР ПО СТРОКАМ:

1. function [J, grad] = costFunction(theta, X, y)
   - Входные параметры:
     * theta - вектор параметров [theta0, theta1, theta2, ...]
     * X - матрица признаков (m строк × n столбцов), каждая строка - один пример
     * y - вектор меток (m × 1), значения 0 или 1
   - Выходные параметры:
     * J - функция стоимости (скаляр)
     * grad - градиент (вектор размерности theta)

2. m = length(y);
   - Количество примеров в обучающей выборке
   - Нужно для нормализации (деление на m)

3. h = sigmoid(X * theta);
   - X * theta - матричное умножение
     Если X = [1 x1 x2; 1 x1 x2; ...] (m × 3)
     и theta = [theta0; theta1; theta2] (3 × 1),
     то X * theta = [theta0 + theta1*x1 + theta2*x2; ...] (m × 1)
   - sigmoid(...) - применяем сигмоиду к каждому элементу
   - h - вектор вероятностей (m × 1), h(i) = P(y=1 | x(i))

4. J = -(1/m) * (y' * log(h) + (1 - y)' * log(1 - h));
   - y' - транспонированный вектор y (1 × m)
   - y' * log(h) - скалярное произведение = SUM(y(i) * log(h(i)))
   - (1 - y)' * log(1 - h) - аналогично для случаев y=0
   - -(1/m) * (...) - усредняем и меняем знак
   - Результат: средняя "цена" ошибки на всех примерах

5. grad = (1/m) * (X' * (h - y));
   - (h - y) - вектор ошибок (m × 1)
   - X' - транспонированная матрица X (n × m)
   - X' * (h - y) - матричное умножение даёт градиент (n × 1)
   - (1/m) - нормализация
   - grad(j) показывает, как изменится J при изменении theta(j)

ТЕОРИЯ:

Функция стоимости (логарифмическая функция потерь):
  J(theta) = -(1/m) * SUM[y*log(h) + (1-y)*log(1-h)]

Почему именно такая формула?

Для одного примера:
- Если y = 1 (реально класс 1):
  J = -log(h)
  * Если h близко к 1 (верно предсказали): log(1) = 0, штраф = 0
  * Если h близко к 0 (ошиблись): log(0) → -∞, штраф огромный!

- Если y = 0 (реально класс 0):
  J = -log(1-h)
  * Если h близко к 0 (верно предсказали): log(1) = 0, штраф = 0
  * Если h близко к 1 (ошиблись): log(0) → -∞, штраф огромный!

Итог: функция "наказывает" за неверные предсказания и "поощряет" верные.

Градиент:
  grad_j = (1/m) * SUM[(h(x) - y) * x_j]

В матричной форме:
  grad = (1/m) * X' * (h - y)

Градиент показывает направление наибольшего роста функции.
Чтобы минимизировать J, идём в противоположном направлении (градиентный спуск).

ЧТО ТАКОЕ НОРМА ГРАДИЕНТА?
---------------------------

В тестах выводится "gradient norm" - это норма (длина) вектора градиента.

Формула: norm(grad) = sqrt(grad(1)^2 + grad(2)^2 + ... + grad(n)^2)

Что это значит:
- Большая норма → градиент большой → функция круто меняется → нужно много шагов для минимизации
- Малая норма → градиент маленький → функция почти не меняется → мы близки к минимуму!

В процессе обучения:
- Начальная норма градиента: обычно большая (например, 0.1-10)
- Финальная норма градиента: должна быть очень маленькой (например, 0.0001-0.001)
- Если финальная норма всё ещё большая → оптимизация не завершилась, нужно больше итераций

Пример из вывода:
  Initial gradient norm: 0.113140  (градиент большой, далеко от минимума)
  Final gradient norm: 0.000315   (градиент почти нулевой, нашли минимум!)

Почему выводим первые 5 элементов?
Градиент может быть очень большим вектором (28 элементов для degree=6).
Выводим первые 5, чтобы увидеть порядок значений, не перегружая вывод.


ФАЙЛ 3: costFunctionReg.m
=========================

ЧТО ДЕЛАЕТ:
То же, что costFunction.m, но с регуляризацией.
Регуляризация предотвращает переобучение (overfitting) при большом количестве признаков.

КОД:
  function [J, grad] = costFunctionReg(theta, X, y, lambda)
  m = length(y);
  
  h = sigmoid(X * theta);
  
  J = -(1/m) * (y' * log(h) + (1 - y)' * log(1 - h)) + (lambda/(2*m)) * (theta(2:end)' * theta(2:end));
  
  grad = (1/m) * (X' * (h - y));
  grad(2:end) = grad(2:end) + (lambda/m) * theta(2:end);
  end

РАЗБОР ПО СТРОКАМ:

1. function [J, grad] = costFunctionReg(theta, X, y, lambda)
   - Дополнительный параметр lambda - коэффициент регуляризации
   - lambda > 0: сильная регуляризация (theta стремятся к 0)
   - lambda = 0: нет регуляризации (как в costFunction.m)

2. h = sigmoid(X * theta);
   - То же самое, что в costFunction.m

3. J = ... + (lambda/(2*m)) * (theta(2:end)' * theta(2:end));
   - Первая часть: обычная функция стоимости (как в costFunction.m)
   - theta(2:end) - все theta кроме первого (индексы с 1 в Octave!)
   - theta(2:end)' * theta(2:end) - сумма квадратов theta_j для j >= 1
   - (lambda/(2*m)) - коэффициент регуляризации
   - Добавляем штраф за большие значения theta

4. grad(2:end) = grad(2:end) + (lambda/m) * theta(2:end);
   - Сначала вычисляем обычный градиент (как в costFunction.m)
   - Затем добавляем регуляризацию только к theta(2:end)
   - theta(1) не регуляризируем (это bias, смещение)

ТЕОРИЯ:

Подробное объяснение регуляризации см. в разделе "ЧТО ТАКОЕ РЕГУЛЯРИЗАЦИЯ?" выше.

Кратко:
- Проблема: переобучение (overfitting) - модель запоминает данные вместо закономерностей
- Решение: добавляем штраф за большие theta в функцию стоимости
- Формула: J_reg = J + (lambda/2m) * SUM(theta_j^2) для j >= 1
- theta_0 не регуляризируем (это bias, не связан с признаками)
- lambda контролирует силу регуляризации

В нашем коде:
  J = обычная_стоимость + (lambda/(2*m)) * (theta(2:end)' * theta(2:end))
  
  theta(2:end) - все theta кроме первого
  theta(2:end)' * theta(2:end) - это SUM(theta_j^2) для j >= 1

Градиент с регуляризацией:
  grad(1) = обычный градиент (без изменений)
  grad(j) = обычный градиент + (lambda/m) * theta(j)    для j >= 2

Эффект: градиент "тянет" theta к нулю, делая модель проще.


ФАЙЛ 4: predict.m
================

ЧТО ДЕЛАЕТ:
Делает предсказание класса (0 или 1) для данных X с использованием обученных параметров theta.

КОД:
  function p = predict(theta, X)
  p = sigmoid(X * theta) >= 0.5;
  end

РАЗБОР ПО СТРОКАМ:

1. function p = predict(theta, X)
   - theta - обученные параметры
   - X - данные для предсказания (может быть один пример или несколько)
   - p - вектор предсказаний (0 или 1)

2. p = sigmoid(X * theta) >= 0.5;
   - sigmoid(X * theta) - вычисляем вероятности
   - >= 0.5 - сравнение: если вероятность >= 0.5, то 1, иначе 0
   - Результат: логический вектор (true/false), который автоматически преобразуется в 1/0

ТЕОРИЯ:

Порог классификации:
После обучения у нас есть вероятность P(y=1 | x) = sigmoid(x * theta).

Правило принятия решения:
- Если P(y=1 | x) >= 0.5 → предсказываем класс 1
- Если P(y=1 | x) < 0.5 → предсказываем класс 0

Почему порог 0.5?
Это стандартный выбор, который минимизирует ошибку классификации.
Можно выбрать другой порог (например, 0.7 для более строгой классификации).

Граница решения:
Граница решения - это множество точек, где P(y=1 | x) = 0.5.
Из уравнения sigmoid(z) = 0.5 получаем z = 0, то есть:
  theta' * x = 0

Для 2 признаков: theta0 + theta1*x1 + theta2*x2 = 0 - это прямая линия.


ФАЙЛ 5: plotData.m
==================

ЧТО ДЕЛАЕТ:
Визуализирует данные - рисует точки двух классов разными маркерами.

КОД:
  function plotData(X, y)
  figure; hold on;
  
  pos = find(y == 1);
  neg = find(y == 0);
  
  plot(X(pos, 1), X(pos, 2), 'k+', 'LineWidth', 2, 'MarkerSize', 7);
  plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize', 7);
  
  hold off;
  end

РАЗБОР ПО СТРОКАМ:

1. function plotData(X, y)
   - X - матрица признаков (m × 2 для 2D визуализации)
   - y - вектор меток (0 или 1)

2. figure; hold on;
   - figure - создаём новое окно для графика
   - hold on - позволяем рисовать несколько графиков в одном окне

3. pos = find(y == 1);
   - find(y == 1) - находим индексы всех примеров с y = 1
   - pos - вектор индексов положительных примеров

4. neg = find(y == 0);
   - Аналогично для отрицательных примеров

5. plot(X(pos, 1), X(pos, 2), 'k+', ...);
   - X(pos, 1) - первый признак для положительных примеров
   - X(pos, 2) - второй признак для положительных примеров
   - 'k+' - чёрные плюсы (k = black, + = plus marker)
   - LineWidth, MarkerSize - размеры маркеров

6. plot(X(neg, 1), X(neg, 2), 'ko', ...);
   - 'ko' - чёрные круги с жёлтой заливкой
   - Аналогично для отрицательных примеров

ТЕОРИЯ:

Визуализация данных помогает:
- Понять, можно ли разделить классы прямой линией (линейная разделимость)
- Увидеть выбросы (outliers)
- Решить, нужны ли полиномиальные признаки

Если классы визуально разделимы прямой линией → простая логистическая регрессия.
Если нет → нужны полиномиальные признаки (как в ex2_reg.m).


ФАЙЛ 6: mapFeature.m
=====================

ЧТО ДЕЛАЕТ:
Создаёт полиномиальные признаки из двух исходных признаков.
Превращает 2 признака в 28 признаков (полиномы до степени 6).

КОД:
  function out = mapFeature(X1, X2)
  degree = 6;
  out = ones(size(X1(:,1)));
  for i = 1:degree
      for j = 0:i
          out(:, end+1) = (X1.^(i-j)).*(X2.^j);
      end
  end
  end

РАЗБОР ПО СТРОКАМ:

1. function out = mapFeature(X1, X2)
   - X1, X2 - векторы исходных признаков (одинаковой длины)
   - out - матрица с полиномиальными признаками

2. degree = 6;
   - Максимальная степень полинома

3. out = ones(size(X1(:,1)));
   - Создаём матрицу, начинающуюся со столбца единиц (для theta_0)
   - size(X1(:,1)) - размер первого столбца X1

4. for i = 1:degree
   - Внешний цикл: степень полинома от 1 до 6

5. for j = 0:i
   - Внутренний цикл: для степени i перебираем все комбинации

6. out(:, end+1) = (X1.^(i-j)).*(X2.^j);
   - X1.^(i-j) - X1 в степени (i-j)
   - X2.^j - X2 в степени j
   - .* - поэлементное умножение
   - end+1 - добавляем новый столбец в конец матрицы
   - Создаём признак: x1^(i-j) * x2^j

Пример для degree = 2:
  i=1, j=0: x1^1 * x2^0 = x1
  i=1, j=1: x1^0 * x2^1 = x2
  i=2, j=0: x1^2 * x2^0 = x1^2
  i=2, j=1: x1^1 * x2^1 = x1*x2
  i=2, j=2: x1^0 * x2^2 = x2^2

Итого: 1, x1, x2, x1^2, x1*x2, x2^2 (6 признаков)

Для degree = 6 получается 28 признаков.

ТЕОРИЯ:

Зачем нужны полиномиальные признаки?
Если данные линейно неразделимы (нельзя разделить прямой линией),
нужна более сложная граница решения.

Полиномиальные признаки позволяют:
- Строить криволинейные границы решения
- Учитывать взаимодействия между признаками (x1*x2)
- Учитывать нелинейные зависимости (x1^2, x2^2)

Проблема:
С увеличением степени растёт количество признаков экспоненциально.
Для degree = 6 из 2 признаков получается 28 признаков.
Это может привести к переобучению → нужна регуляризация!


ФАЙЛ 7: ex2.m
=============

ЧТО ДЕЛАЕТ:
Основной скрипт для простой логистической регрессии (без регуляризации).
Решает задачу предсказания поступления студента по баллам экзаменов.

КОД С РАЗБОРОМ:

1. clear; close all; clc
   - Очищаем переменные, закрываем графики, очищаем консоль

2. data = load('ex2data1.txt');
   - Загружаем данные из файла
   - Формат: столбец 1 = балл экзамена 1, столбец 2 = балл экзамена 2, столбец 3 = метка (0/1)

3. X = data(:, [1, 2]); y = data(:, 3);
   - X - матрица признаков (100 × 2)
   - y - вектор меток (100 × 1)

4. plotData(X, y);
   - Визуализируем данные
   - Видим, что классы можно разделить прямой линией

5. [m, n] = size(X);
   - m = 100 (количество примеров)
   - n = 2 (количество признаков)

6. X = [ones(m, 1) X];
   - Добавляем столбец единиц в начало
   - Теперь X = [1 x1 x2; 1 x1 x2; ...] (100 × 3)
   - Единицы нужны для theta_0 (bias)

7. initial_theta = zeros(n + 1, 1);
   - Инициализируем theta нулями
   - Размерность: 3 × 1 (theta0, theta1, theta2)

8. [cost, grad] = costFunction(initial_theta, X, y);
   - Вычисляем начальную стоимость и градиент
   - При theta = [0, 0, 0] гипотеза h = sigmoid(0) = 0.5 для всех примеров
   - Стоимость J = -log(0.5) = ln(2) ≈ 0.693

9. options = optimset('GradObj', 'on', 'MaxIter', 400);
   - Настройки оптимизатора:
     * 'GradObj', 'on' - мы предоставляем градиент (быстрее и точнее)
     * 'MaxIter', 400 - максимум 400 итераций

10. [theta, cost] = fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);
    - fminunc - функция минимизации
    - @(t)(costFunction(t, X, y)) - анонимная функция (замыкание)
    - Находит theta, которые минимизируют J
    - Использует градиентный спуск или более продвинутые методы (BFGS)

11. prob = sigmoid([1 45 85] * theta);
    - Предсказание для конкретного студента
    - [1 45 85] - вектор признаков (1 для bias, 45 и 85 - баллы)
    - Результат: вероятность поступления ≈ 0.776 (77.6%)

12. p = predict(theta, X);
    - Предсказания для всех примеров обучающей выборки

13. mean(double(p == y)) * 100
    - p == y - логический вектор (true где предсказание верно)
    - double(...) - преобразуем в числа (1/0)
    - mean(...) - среднее = доля верных предсказаний
    - * 100 - в проценты
    - Результат: 89% точность

РЕЗУЛЬТАТЫ (РАЗБОР КОНКРЕТНОГО ВЫВОДА):
----------------------------------------

Пример вывода при запуске ex2.m:

  Cost at initial theta (zeros): 0.693147
  Gradient at initial theta (zeros):
   -0.100000 
   -12.009217 
   -11.262842 

  Cost at theta found by fminunc: 0.203498
  theta:
   -25.161272 
   0.206233 
   0.201470 

  For a student with scores 45 and 85, admission probability: 0.776289
  Train Accuracy: 89.000000

РАЗБОР ПО СТРОКАМ:

1. Cost at initial theta (zeros): 0.693147
   - При theta = [0, 0, 0] гипотеза h = sigmoid(0) = 0.5 для всех примеров
   - J = -log(0.5) = ln(2) ≈ 0.693147
   - Это максимальная неопределённость - модель ничего не знает
   - Все предсказания равны 0.5 (50% вероятность)

2. Gradient at initial theta (zeros):
   -0.100000    (градиент для theta_0)
   -12.009217   (градиент для theta_1 - балл экзамена 1)
   -11.262842   (градиент для theta_2 - балл экзамена 2)
   
   Что это значит?
   - Отрицательные значения → нужно УВЕЛИЧИВАТЬ theta (идём против градиента)
   - Большие по модулю значения (-12, -11) → эти признаки важны!
   - Градиент показывает направление для минимизации функции стоимости

3. Cost at theta found by fminunc: 0.203498
   - После оптимизации стоимость упала с 0.693 до 0.203
   - Уменьшение в ~3.4 раза → модель научилась!
   - Чем меньше J, тем лучше предсказания

4. theta:
   -25.161272   (theta_0 - bias, смещение)
   0.206233     (theta_1 - вес признака "балл экзамена 1")
   0.201470     (theta_2 - вес признака "балл экзамена 2")
   
   Интерпретация:
   - theta_0 = -25.16 - большое отрицательное смещение
   - theta_1 ≈ theta_2 ≈ 0.2 - оба экзамена примерно равнозначны
   - Уравнение границы решения:
     -25.16 + 0.206*x1 + 0.201*x2 = 0
     x2 = (25.16 - 0.206*x1) / 0.201
   - Это прямая линия, разделяющая классы

5. For a student with scores 45 and 85, admission probability: 0.776289
   - Вычисляем: sigmoid(-25.16 + 0.206*45 + 0.201*85)
   - = sigmoid(-25.16 + 9.28 + 17.12)
   - = sigmoid(1.24)
   - = 1 / (1 + e^(-1.24))
   - ≈ 0.776 (77.6%)
   - Студент с баллами 45 и 85 имеет 77.6% шанс поступить

6. Train Accuracy: 89.000000
   - Модель правильно классифицировала 89 из 100 студентов
   - 89% - хороший результат для простой линейной границы
   - 11 студентов неправильно классифицированы (возможно, выбросы)

ВЫВОДЫ:
- Модель успешно обучилась (стоимость упала с 0.693 до 0.203)
- Оба экзамена примерно равнозначны (theta_1 ≈ theta_2)
- Точность 89% - хороший результат
- Граница решения - прямая линия (линейная разделимость)


ФАЙЛ 8: ex2_reg.m
=================

ЧТО ДЕЛАЕТ:
Скрипт для регуляризованной логистической регрессии.
Решает задачу классификации микрочипов (данные линейно неразделимы).

КОД С РАЗБОРОМ:

1. data = load('ex2data2.txt');
   - Загружаем данные о тестировании микрочипов
   - 118 примеров, 2 признака (результаты тестов), метка (годен/брак)

2. X = mapFeature(X(:,1), X(:,2));
   - Преобразуем 2 признака в 28 полиномиальных признаков
   - Данные линейно неразделимы → нужны полиномы

3. initial_theta = zeros(size(X, 2), 1);
   - Инициализируем theta нулями
   - Размерность: 28 × 1 (28 признаков после mapFeature)

4. lambda = 1;
   - Параметр регуляризации
   - lambda = 1 - умеренная регуляризация (хороший баланс)

5. [cost, grad] = costFunctionReg(initial_theta, X, y, lambda);
   - Используем версию с регуляризацией
   - Начальная стоимость та же (0.693), т.к. theta = 0

6. [theta, J, exit_flag] = fminunc(...);
   - Оптимизация с регуляризацией
   - exit_flag - флаг успешности оптимизации

7. p = predict(theta, X);
   - Предсказания

8. mean(double(p == y)) * 100
   - Точность: 83%

РЕЗУЛЬТАТЫ:
- Начальная стоимость: 0.693
- Точность: 83%
- Граница решения - сложная кривая (не прямая линия)

ПОЧЕМУ ТОЧНОСТЬ НИЖЕ, ЧЕМ В ex2.m?
- Данные сложнее (нелинейная граница)
- Регуляризация немного снижает точность на обучающих данных,
  но улучшает обобщающую способность (меньше переобучение)


ОПТИМИЗАТОР FMINUNC
===================

Что делает:
Минимизирует функцию, используя градиент.

Синтаксис:
  [theta, cost] = fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);

Параметры:
- @(t)(costFunction(t, X, y)) - функция, которую минимизируем
  @(t) - анонимная функция с параметром t
  Это позволяет передать X и y в costFunction
- initial_theta - начальное приближение
- options - настройки оптимизации

Почему используем fminunc вместо ручного градиентного спуска?
- Автоматически подбирает learning rate
- Использует продвинутые алгоритмы (BFGS, L-BFGS)
- Быстрее сходится
- Не нужно писать циклы

Альтернатива (ручной градиентный спуск):
  for iter = 1:max_iter
    [J, grad] = costFunction(theta, X, y);
    theta = theta - alpha * grad;  % alpha - learning rate
  end

Но нужно подбирать alpha вручную, что сложно.


ВЕКТОРИЗАЦИЯ
============

Что это:
Использование матричных операций вместо циклов.

Почему важно:
1. Код короче и понятнее
2. Намного быстрее (Octave/Matlab оптимизированы для матриц)
3. Меньше ошибок

Пример - вычисление градиента:

НЕ векторизованно (медленно):
  grad = zeros(size(theta));
  for j = 1:length(theta)
    sum = 0;
    for i = 1:m
      sum = sum + (h(i) - y(i)) * X(i, j);
    end
    grad(j) = sum / m;
  end

Векторизованно (быстро):
  grad = (1/m) * (X' * (h - y));

Операция X' * (h - y) делает всё за один раз!

Размерности:
- X: (m × n)
- X': (n × m)
- (h - y): (m × 1)
- X' * (h - y): (n × 1) = grad

Это эквивалентно циклу, но выполняется за одну операцию!


КАК ЗАПУСКАТЬ И ТЕСТИРОВАТЬ
============================

СПОСОБ 1: ИСПОЛЬЗОВАНИЕ MAKEFILE (РЕКОМЕНДУЕТСЯ)
------------------------------------------------

Создан Makefile для удобного запуска с графиками:

  cd mlclass-ex2
  make help              # показать справку
  make ex2               # простая регрессия (с графиками)
  make ex2_reg           # с регуляризацией (с графиками)
  make test_lambda       # тест разных lambda (с графиками)
  make test_degree       # тест разных degree (с графиками)
  make test_without_reg  # без регуляризации (с графиками)
  make all               # запустить все основные тесты
  make clean             # удалить временные файлы

Преимущества Makefile:
- Графики показываются автоматически (--persist)
- Цветной вывод для удобства
- Простые команды (make ex2 вместо длинной команды octave)

СПОСОБ 2: НАПРЯМУЮ ЧЕРЕЗ OCTAVE
--------------------------------

1. БЕЗ регуляризации (простая логистическая регрессия):
   cd mlclass-ex2
   octave --persist --eval "ex2"
   
   Или в интерактивном режиме:
   octave
   >> ex2

2. С регуляризацией (по умолчанию lambda = 1):
   octave --persist --eval "ex2_reg"
   
   Или:
   octave
   >> ex2_reg

ВАЖНО: Используйте --persist вместо --no-gui, чтобы графики показывались!

ТЕСТИРОВАНИЕ С РАЗНЫМИ LAMBDA
------------------------------

С Makefile:
  make test_lambda

Или напрямую:
  octave --persist --eval "test_lambda"

Или в интерактивном режиме:
  octave
  >> test_lambda

Что делает:
- Тестирует lambda = [0, 0.01, 0.1, 1, 10, 100]
- Для каждого lambda показывает:
  * Начальную стоимость и норму градиента
  * Первые 5 элементов градиента
  * Финальную стоимость и норму градиента
  * Точность (accuracy)
  * График с границей решения

Результаты:
- lambda = 0:    Переобучение, граница очень извилистая
- lambda = 0.01: Слабая регуляризация
- lambda = 1:    Хороший баланс (по умолчанию)
- lambda = 10:   Сильная регуляризация
- lambda = 100:  Слишком сильная, граница почти прямая

КАК ИЗМЕНИТЬ LAMBDA ВРУЧНУЮ
----------------------------

В файле ex2_reg.m найдите строку:
  lambda = 1;

Измените на нужное значение:
  lambda = 0;      % без регуляризации
  lambda = 0.1;    % слабая
  lambda = 10;     % сильная
  lambda = 100;    % очень сильная

Затем запустите:
  make ex2_reg
  
  Или:
  octave --persist --eval "ex2_reg"

ТЕСТИРОВАНИЕ БЕЗ РЕГУЛЯРИЗАЦИИ
-------------------------------

С Makefile:
  make test_without_reg

Или напрямую:
  octave --persist --eval "test_without_reg"

Что делает:
- Использует lambda = 0 (без регуляризации)
- Показывает начальную и финальную стоимость
- Показывает начальную и финальную норму градиента
- Показывает первые 5 элементов градиента
- Показывает, как модель переобучается
- Граница решения будет очень извилистой

СРАВНЕНИЕ: БЕЗ vs С РЕГУЛЯРИЗАЦИЕЙ
-----------------------------------

Создан скрипт test_reg_comparison.m для сравнения результатов:

С Makefile:
  make test_reg_comparison

Или напрямую:
  octave --persist --eval "test_reg_comparison"

Что делает:
- Запускает два теста на одних и тех же данных:
  1. БЕЗ регуляризации (lambda = 0)
  2. С регуляризацией (lambda = 1)
- Показывает для каждого:
  * Начальную и финальную стоимость
  * Норму градиента
  * Первые 5 элементов градиента
  * Точность
- Выводит сравнение результатов
- Показывает два графика рядом для визуального сравнения

Пример вывода:
  Без регуляризации:  Accuracy = 86.44%,  Cost = 0.283712
  С регуляризацией:  Accuracy = 83.05%,  Cost = 0.529004
  Разница в точности: 3.39%

Что видим:
- Без регуляризации точность выше на обучающих данных (86.44% vs 83.05%)
- Но это переобучение! Модель запомнила данные вместо закономерностей
- С регуляризацией точность чуть ниже, но модель лучше обобщается
- Граница решения без регуляризации очень извилистая (переобучение)
- Граница решения с регуляризацией более плавная (лучше для новых данных)

ТЕСТИРОВАНИЕ С РАЗНЫМИ DEGREE (СТЕПЕНЯМИ ПОЛИНОМА)
---------------------------------------------------

С Makefile:
  make test_degree

Или напрямую:
  octave --persist --eval "test_degree"

Что делает:
- Тестирует degree = [1, 2, 3, 4, 5, 6]
- Для каждого degree показывает:
  * Количество признаков
  * Начальную стоимость и норму градиента
  * Первые 5 элементов градиента
  * Финальную стоимость и норму градиента
  * Точность
  * График с границей решения

Результаты:
- degree = 1: 3 признака (1, x1, x2) - прямая линия
- degree = 2: 6 признаков (1, x1, x2, x1², x1*x2, x2²) - парабола
- degree = 3: 10 признаков - более сложная кривая
- degree = 6: 28 признаков (по умолчанию) - очень сложная кривая

КАК ИЗМЕНИТЬ DEGREE ВРУЧНУЮ
----------------------------

В файле mapFeature.m найдите строку:
  degree = 6;

Измените на нужное значение:
  degree = 1;   % только линейные признаки
  degree = 2;   % квадратичные
  degree = 3;   % кубические
  degree = 6;   % до 6 степени (по умолчанию)

Затем запустите ex2_reg.m:
  octave --no-gui --eval "ex2_reg"

ВАЖНО:
После изменения degree нужно перезапустить скрипт, т.к. mapFeature вызывается внутри.

СРАВНЕНИЕ РЕЗУЛЬТАТОВ
---------------------

Рекомендуется запустить все тесты и сравнить:

1. test_without_reg.m - без регуляризации
   Ожидаем: высокая точность на обучающих данных, но переобучение

2. ex2_reg.m - с lambda = 1 (по умолчанию)
   Ожидаем: хороший баланс

3. test_lambda.m - разные lambda
   Ожидаем: видим, как меняется граница решения

4. test_degree.m - разные степени полинома
   Ожидаем: видим, как сложность границы зависит от degree

ЗАМЕТКИ
-------

- При degree = 1 граница всегда прямая (даже с регуляризацией)
- При больших degree (4, 5, 6) обязательно нужна регуляризация!
- Без регуляризации и с большим degree модель переобучится
- Оптимальные значения: degree = 6, lambda = 1 (для наших данных)


КЛЮЧЕВЫЕ ФОРМУЛЫ
================

Сигмоида:
  g(z) = 1 / (1 + e^(-z))

Гипотеза:
  h = sigmoid(X * theta)

Функция стоимости:
  J = -(1/m) * [y' * log(h) + (1-y)' * log(1-h)]

Градиент:
  grad = (1/m) * X' * (h - y)

С регуляризацией:
  J_reg = J + (lambda/2m) * theta(2:end)' * theta(2:end)
  grad_reg(2:end) = grad(2:end) + (lambda/m) * theta(2:end)

Предсказание:
  p = (sigmoid(X * theta) >= 0.5)
