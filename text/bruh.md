# Ответы на вопросы по анализу текста

## Вопрос 4.8: Как TF-IDF повышает релевантность результатов поиска?

**TF-IDF (Term Frequency-Inverse Document Frequency)** повышает релевантность результатов поиска следующим образом:

1. **Балансировка частоты термина и его редкости**: TF-IDF учитывает не только то, как часто термин появляется в документе (TF), но и насколько он редок во всей коллекции документов (IDF).

2. **Снижение веса общих слов**: Слова, которые часто встречаются во многих документах (например, "the", "and", "is"), получают более низкие оценки IDF, что предотвращает их доминирование в результатах поиска.

3. **Выделение отличительных терминов**: Термины, которые часто встречаются в конкретном документе, но редки в корпусе, получают высокие оценки TF-IDF, что делает их более релевантными для этого документа.

4. **Повышение точности**: Выделяя термины, характерные для документа, а не общие, TF-IDF помогает поисковым системам возвращать более точные и релевантные результаты.

**Формула**: TF-IDF(t,d) = TF(t,d) × IDF(t)
- TF(t,d) = частота термина t в документе d
- IDF(t) = log(общее количество документов / количество документов, содержащих термин t)

## Вопрос 4.9: Зачем нужно уменьшать размерность в анализе текста? Как этого достичь?

### Зачем уменьшать размерность:

1. **Проклятие размерности**: Высокомерные пространства (тысячи признаков/слов) делают анализ вычислительно дорогим и склонным к переобучению.

2. **Уменьшение шума**: Многие размерности представляют шум или нерелевантные вариации, а не значимые паттерны.

3. **Вычислительная эффективность**: Меньшая размерность означает более быструю обработку, меньшее использование памяти и более эффективные алгоритмы.

4. **Лучшая обобщающая способность**: Уменьшение размерности помогает моделям лучше обобщаться на новые данные, фокусируясь на наиболее важных признаках.

5. **Интерпретируемость**: Представления с меньшей размерностью легче визуализировать и понимать.

### Как достичь уменьшения размерности:

1. **Отбор признаков**:
   - Удаление стоп-слов (общих слов, таких как "the", "and")
   - Использование статистических методов (хи-квадрат, взаимная информация)
   - Выбор топ N признаков по частоте или TF-IDF

2. **Извлечение/трансформация признаков**:
   - **PCA (Principal Component Analysis)**: Линейное преобразование в пространство меньшей размерности
   - **LSA (Latent Semantic Analysis)**: Использует SVD для поиска скрытых семантических размерностей
   - **Тематическое моделирование**: LDA (Latent Dirichlet Allocation) для уменьшения до размерностей тем
   - **Векторные представления слов**: Представление слов в виде плотных векторов (Word2Vec, GloVe, BERT)

3. **Стемминг/лемматизация**: Приведение вариаций слов к корневым формам

4. **Пороговые значения**: Удаление терминов, которые встречаются в слишком малом или слишком большом количестве документов

## Вопрос 4.10: Анализ текста для банка Yoyodyne

### (a) Как банк Yoyodyne должен проводить такой анализ текста?

**Пошаговый подход:**

1. **Сбор данных**:
   - Настройка API или инструментов веб-скрапинга для сбора постов из Twitter, Facebook, Google+
   - Фильтрация постов, упоминающих "Yoyodyne Bank" или релевантные ключевые слова
   - Сбор метаданных (дата, пользователь, метрики вовлеченности)

2. **Предобработка данных**:
   - Очистка текста (удаление URL, хештегов, специальных символов)
   - Токенизация
   - Удаление стоп-слов
   - Применение стемминга/лемматизации
   - Обработка многоязычного контента (если применимо)

3. **Техники анализа текста**:
   - **Анализ тональности**: Классификация постов как позитивных, негативных или нейтральных
   - **Тематическое моделирование**: Использование LDA или аналогичных методов для выявления ключевых тем/проблем
   - **Извлечение ключевых слов**: Выявление наиболее упоминаемых тем
   - **Анализ TF-IDF**: Поиск отличительных терминов в отзывах клиентов
   - **Распознавание именованных сущностей**: Выявление конкретных продуктов, услуг, мест, упомянутых в тексте

4. **Анализ и визуализация**:
   - Создание облаков слов для разных категорий тональности
   - Генерация временных рядов трендов тональности
   - Категоризация отзывов по темам (комиссии, обслуживание клиентов, продукты и т.д.)
   - Сравнение тональности на разных платформах

5. **Практические выводы**:
   - Выявление общих жалоб и точек похвалы
   - Отслеживание изменений тональности во времени
   - Приоритизация областей для улучшения
   - Мониторинг реакции на изменения в услугах

### (b) Преимущества и вызовы

**Преимущества:**
1. **Обратная связь в реальном времени**: Получение немедленных инсайтов из мнений клиентов
2. **Большой размер выборки**: Доступ к огромному количеству отзывов клиентов
3. **Экономическая эффективность**: Менее затратно, чем традиционные опросы
4. **Несмещенные данные**: Клиенты добровольно выражают мнения (нет смещения опросов)
5. **Выявление трендов**: Отслеживание изменений тональности клиентов во времени
6. **Конкурентная разведка**: Сравнение с упоминаниями конкурентов

**Вызовы:**
1. **Качество данных**: Шумный, неформальный язык, сленг, сокращения
2. **Двусмысленность тональности**: Сарказм, ирония, контекстно-зависимое значение
3. **Объем и масштаб**: Большие объемы данных, требующие эффективной обработки
4. **Проблемы конфиденциальности**: Этические и правовые соображения при сборе данных
5. **Многоязычный контент**: Необходимость перевода и кросс-языкового анализа
6. **Спам и боты**: Фильтрация поддельного или рекламного контента
7. **Репрезентативность**: Пользователи социальных сетей могут не представлять всю клиентскую базу
8. **Потеря контекста**: Короткие посты могут не иметь контекста
9. **Техническая сложность**: Требует экспертизы в NLP и обработке данных
10. **Ограничения платформ**: Ограничения API, лимиты скорости, изменяющиеся политики платформ

## Вопрос 4.11: Анализ мешка слов и стемминга

### Данный отзыв:
"Sneaky Fees!

Do you carefully read every word on your statement and every notice your bank every sent you? If you've missed one, Yoyodyne Bank is NOT the bank for you! Close all your accounts especially if you're going overseas!!"

### (a) Мешок слов (без учета регистра, стоп-слова удалены)

После удаления стоп-слов из списка стоп-слов Snowball English, мешок слов будет следующим:

**Слова (без учета регистра, стоп-слова удалены):**
- sneaky
- fees
- carefully
- read
- word
- statement
- notice
- bank
- sent
- missed
- yoyodyne
- bank (появляется дважды в оригинале)
- close
- accounts
- especially
- going
- overseas

**Примечание**: "bank" появляется дважды в оригинальном тексте, но в истинном представлении мешка слов будет считаться один раз (хотя может иметь частоту = 2).

**Мешок слов, отсортированный по алфавиту:**
accounts, bank, carefully, close, especially, fees, going, missed, notice, overseas, read, sent, sneaky, statement, word, yoyodyne

### (b) Мешок слов со стеммингом

Используя алгоритм стемминга Портера (Snowball stemmer), мешок слов со стеммингом будет следующим:

**Оригинал → Стемминг:**
- sneaky → sneaki
- fees → fee
- carefully → care
- read → read
- word → word
- statement → statement
- notice → notic
- bank → bank
- sent → sent
- missed → miss
- yoyodyne → yoyodyn
- bank → bank
- close → close
- accounts → account
- especially → especi
- going → go
- overseas → oversea

**Мешок слов со стеммингом, отсортированный по алфавиту:**
account, bank, care, close, especi, fee, go, miss, notic, oversea, read, sent, sneaki, statement, word, yoyodyn

## Вопрос 4.12: Анализ статьи с использованием частот и TF-IDF

### (a) 10 репрезентативных слов из статьи

Прочитав статью о OPEC и производстве нефти, 10 репрезентативных слов:
1. OPEC
2. oil (нефть)
3. production (производство)
4. prices (цены)
5. meeting (встреча)
6. market (рынок)
7. demand (спрос)
8. analysts (аналитики)
9. quota (квота)
10. output (выпуск)

### (b) Облако слов из 20 наиболее частых слов (без предобработки)

Создается с использованием простой частоты терминов без удаления стоп-слов, пунктуации и чисел.

### (c) Облако слов из 20 наиболее частых слов (с предобработкой)

Создается с удалением стоп-слов, пунктуации и чисел, что делает облако слов более информативным и фокусированным на содержательных словах.

### (d) Облако слов из 20 слов с наивысшими значениями TF-IDF (без предобработки)

Использует взвешивание TF-IDF для выявления терминов, которые являются отличительными для данного документа по сравнению с остальным корпусом, даже без предобработки.

### (e) Облако слов из 20 слов с наивысшими значениями TF-IDF (с предобработкой)

Комбинирует взвешивание TF-IDF с предобработкой (удаление стоп-слов, пунктуации, чисел), что дает наилучшие результаты для выявления наиболее важных и отличительных терминов в документе.

### (f) Сравнение 4 облаков слов и списка слов из части (a)

**Ключевые наблюдения:**

1. **Влияние предобработки**:
   - Сравнение (b) vs (c) и (d) vs (e) показывает, что предобработка значительно улучшает качество облаков слов
   - Стоп-слова доминируют в версиях без предобработки
   - Версии с предобработкой фокусируются на содержательных словах

2. **Влияние взвешивания TF-IDF**:
   - Сравнение (b) vs (d) и (c) vs (e) демонстрирует, что TF-IDF помогает выявить документо-специфичные термины
   - Простая частота благоприятствует общим словам, которые встречаются во многих документах
   - TF-IDF подчеркивает термины, которые отличительны для документа

3. **Соответствие ручному отбору**:
   - Облако слов (e) должно иметь наилучшее совпадение с вручную выбранными словами
   - Слова вроде "opec", "oil", "production", "prices" должны появляться в обоих случаях
   - TF-IDF с предобработкой лучше всего отражает человеческое понимание тем документа

4. **Практические выводы**:
   - **Для поиска и извлечения**: TF-IDF с предобработкой является оптимальным
   - **Для быстрого обзора**: Простая частота с предобработкой (часть c) достаточна
   - **Для детального анализа**: TF-IDF с предобработкой (часть e) предоставляет наибольшие инсайты
   - **Для общего использования**: Всегда применяйте предобработку; TF-IDF когда важен контекст корпуса

**Заключение:**

Сравнение демонстрирует, что:
1. **Предобработка критически важна**: Удаление стоп-слов, пунктуации и чисел значительно улучшает качество анализа
2. **TF-IDF повышает релевантность**: Выявляет термины, которые отличительны для документа, а не просто частые
3. **Лучший подход**: TF-IDF с предобработкой (часть e) предоставляет наиболее значимое представление содержания документа
4. **Человеческая интуиция**: Вручную выбранные слова лучше всего соответствуют подходу TF-IDF + предобработка, подтверждая, что он отражает человеческое понимание тем документа

