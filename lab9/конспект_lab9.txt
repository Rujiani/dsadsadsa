================================================================================
                    КОНСПЕКТ: ДЕРЕВЬЯ РЕШЕНИЙ (Decision Trees)
                              Лабораторная работа 9
================================================================================

--------------------------------------------------------------------------------
                         ЧАСТЬ 1: ТЕОРЕТИЧЕСКИЕ ОСНОВЫ
--------------------------------------------------------------------------------

ЧТО ТАКОЕ ДЕРЕВО РЕШЕНИЙ?
=========================

Дерево решений — это метод машинного обучения для классификации (и регрессии).
Представь, что ты играешь в игру "20 вопросов" — задаёшь вопросы да/нет и 
постепенно угадываешь ответ. Дерево решений работает точно так же.

Структура дерева:
- Корень (root) — начальный узел, первый вопрос
- Внутренние узлы (nodes) — промежуточные вопросы
- Листья (leaves) — конечные ответы (классы)
- Рёбра (branches) — связи между узлами (ответы на вопросы)

Пример:
                    [Income > 45?]
                     /          \
                   Да           Нет
                   /              \
           [Age > 30?]         Класс 0
            /      \
          Да       Нет
          /          \
      Класс 1     Класс 0


ЗАЧЕМ НУЖНЫ ДЕРЕВЬЯ РЕШЕНИЙ?
============================

1. Интерпретируемость — легко понять, почему модель приняла решение
2. Не требуют нормализации данных
3. Работают с категориальными и числовыми признаками
4. Автоматически выполняют feature selection (отбор признаков)
5. Визуально понятны даже не-специалистам


КРИТЕРИИ РАЗБИЕНИЯ (SPLITTING CRITERIA)
=======================================

Когда дерево "решает", по какому признаку разбить данные, оно использует
математические критерии. Цель — получить наиболее "чистые" группы.

1. INFORMATION GAIN (Прирост информации)
   ------------------------------------
   Основан на понятии энтропии из теории информации.
   
   Энтропия — мера "беспорядка" или неопределённости в данных.
   
   Формула энтропии:
   H(S) = -Σ p(i) * log2(p(i))
   
   где p(i) — доля класса i в наборе S
   
   Пример:
   - Если все элементы одного класса → энтропия = 0 (порядок)
   - Если 50% класс 0 и 50% класс 1 → энтропия = 1 (максимум хаоса)
   
   Information Gain = H(до разбиения) - H(после разбиения)
   
   Чем больше Information Gain, тем лучше разбиение!

2. GINI COEFFICIENT (Коэффициент Джини)
   ------------------------------------
   Альтернативный критерий, измеряет "нечистоту" узла.
   
   Формула:
   Gini = 1 - Σ p(i)²
   
   где p(i) — доля класса i
   
   Пример:
   - Если все элементы одного класса → Gini = 0 (чисто)
   - Если 50%/50% → Gini = 0.5 (максимум нечистоты)
   
   Выбирается разбиение с МИНИМАЛЬНЫМ Gini.

Различия Information Gain vs Gini:
- Gini быстрее вычисляется (нет логарифма)
- Information Gain чуть лучше для несбалансированных классов
- На практике результаты часто похожи


КРОСС-ВАЛИДАЦИЯ (Cross-Validation)
==================================

Проблема: как понять, что модель хорошо обобщает на новые данные?

Решение: кросс-валидация!

K-fold Cross-Validation (K-кратная):
1. Делим данные на K частей (folds)
2. K раз обучаем модель:
   - Каждый раз одна часть — тестовая
   - Остальные K-1 частей — обучающие
3. Усредняем результаты

Пример 3-fold CV:
Итерация 1: Train=[2,3], Test=[1]
Итерация 2: Train=[1,3], Test=[2]
Итерация 3: Train=[1,2], Test=[3]

Зачем? Чтобы оценить, как модель будет работать на НОВЫХ данных,
которые она не видела при обучении.


--------------------------------------------------------------------------------
                         ЧАСТЬ 2: МЕТРИКИ КАЧЕСТВА
--------------------------------------------------------------------------------

CONFUSION MATRIX (Матрица ошибок)
=================================

Это таблица 2x2, показывающая результаты классификации:

                        Predicted
                      0         1
                 +----------+----------+
Actual    0      |    TN    |    FP    |
                 +----------+----------+
          1      |    FN    |    TP    |
                 +----------+----------+

TN (True Negative)  — правильно предсказан класс 0
TP (True Positive)  — правильно предсказан класс 1
FN (False Negative) — ошибка: было 1, предсказали 0
FP (False Positive) — ошибка: было 0, предсказали 1


ACCURACY (Точность)
===================

Accuracy = (TP + TN) / (TP + TN + FP + FN)

Простыми словами: доля правильных ответов.


RESUBSTITUTION ERROR RATE
=========================

Resubstitution Error = 1 - Accuracy

Это ошибка модели на ОБУЧАЮЩИХ данных (тех же, на которых училась).

ВАЖНО: Это ПЛОХОЙ показатель реальной производительности!

Почему? Потому что модель уже "видела" эти данные при обучении.
Это как проверять знания студента на вопросах, которые он уже решал.
Модель может просто "запомнить" данные (overfitting), но плохо 
работать на новых.

Лучше использовать:
- Test error (на отложенных данных)
- Cross-validation error


ROC CURVE (Receiver Operating Characteristic)
=============================================

ROC-кривая показывает баланс между:
- TPR (True Positive Rate) = TP / (TP + FN) — чувствительность
- FPR (False Positive Rate) = FP / (FP + TN) — 1 - специфичность

Как строится:
1. Модель выдаёт вероятности (не просто 0/1)
2. Меняем порог (threshold) от 0 до 1
3. Для каждого порога считаем TPR и FPR
4. Рисуем точки (FPR, TPR)

Интерпретация:
- Диагональ (линия от 0,0 до 1,1) — случайный классификатор
- Чем ближе к левому верхнему углу — тем лучше
- Идеальная модель проходит через точку (0, 1)


AUC (Area Under Curve)
======================

AUC — площадь под ROC-кривой.

Значения:
- AUC = 0.5 — модель не лучше подбрасывания монетки
- AUC = 0.7-0.8 — приемлемая модель
- AUC = 0.8-0.9 — хорошая модель
- AUC = 0.9-1.0 — отличная модель

Полезность AUC:
1. Не зависит от выбора порога
2. Работает для несбалансированных классов
3. Единое число для сравнения моделей
4. Инвариантен к масштабированию предсказаний


--------------------------------------------------------------------------------
                         ЧАСТЬ 3: PRUNING (Обрезка)
--------------------------------------------------------------------------------

ЧТО ТАКОЕ PRUNING?
==================

Pruning (обрезка) — техника уменьшения размера дерева путём удаления
ветвей с низкой предсказательной силой.

Зачем нужна?

1. Борьба с переобучением (overfitting)
   - Большое дерево может "запомнить" обучающие данные
   - Маленькое дерево лучше обобщает

2. Упрощение модели
   - Легче интерпретировать
   - Быстрее работает
   - Меньше памяти

3. Уменьшение шума
   - Глубокие ветви могут ловить случайные паттерны


COMPLEXITY PARAMETER (CP)
=========================

CP — параметр сложности в rpart.

Формула штрафа:
R_cp(T) = R(T) + cp * |T|

где:
- R(T) — ошибка дерева T
- |T| — количество листьев
- cp — штраф за каждый лист

Как это работает:
- cp = 0 → нет штрафа, дерево растёт максимально
- cp большой → сильный штраф, дерево маленькое

Выбор CP:
Смотрим таблицу printcp() и выбираем CP с минимальной 
cross-validation error (xerror).


ПОДРОБНОЕ ОБЪЯСНЕНИЕ: CP, XERROR, CV
====================================

ЧТО ТАКОЕ CP (Complexity Parameter)?
------------------------------------
CP — это "штраф" за сложность дерева.

Представь: ты строишь дерево и можешь добавить ещё одно разбиение.
Вопрос: стоит ли?

CP помогает ответить:
- Если новое разбиение улучшает ошибку НА МНОГО → добавляем
- Если улучшение маленькое → НЕ добавляем (штраф CP больше выгоды)

Пример:
- CP = 0.01 означает: "Добавляй разбиение только если оно уменьшит
  ошибку больше чем на 1%"
- CP = 0.1 означает: "Добавляй только если улучшение > 10%"

В таблице printcp() каждая строка — это дерево с разным CP.
Чем больше CP, тем проще дерево (меньше разбиений).


ЧТО ТАКОЕ CV (Cross-Validation)?
----------------------------------
CV = Кросс-валидация — способ проверить, как модель работает
на НОВЫХ данных, которые она не видела.

Как работает 3-fold CV:
1. Делим данные на 3 части (fold 1, fold 2, fold 3)
2. Обучаем модель 3 раза:
   - Итерация 1: train на fold 2+3, test на fold 1
   - Итерация 2: train на fold 1+3, test на fold 2
   - Итерация 3: train на fold 1+2, test на fold 3
3. Считаем среднюю ошибку на всех тестовых частях

Зачем это нужно?
- Модель может "запомнить" обучающие данные (overfitting)
- CV показывает, как модель работает на данных, которые не видела
- Это честная оценка реальной производительности!


ЧТО ТАКОЕ XERROR (Cross-Validation Error)?
-------------------------------------------
XERROR = ошибка кросс-валидации.

Это ошибка модели, посчитанная через CV (кросс-валидацию).

В таблице printcp() есть две ошибки:
1. REL ERROR (relative error) — ошибка на ОБУЧАЮЩИХ данных
   - Модель видела эти данные при обучении
   - Может быть занижена из-за overfitting
   
2. XERROR — ошибка на ТЕСТОВЫХ данных (через CV)
   - Модель НЕ видела эти данные при обучении
   - Более честная оценка!

Почему XERROR важнее?
- REL ERROR может быть обманчивым (overfitting)
- XERROR показывает реальную производительность на новых данных
- Выбираем дерево с МИНИМАЛЬНЫМ XERROR!


ПРИМЕР ИЗ ТАБЛИЦЫ:
------------------
        CP nsplit rel error  xerror     xstd
1 0.692308      0   1.00000 1.00000 0.046685
2 0.025000      1   0.30769 0.31154 0.032194
3 0.011538      3   0.25769 0.29231 0.031335
4 0.010256      5   0.23462 0.24231 0.028881  ← МИНИМУМ XERROR!
5 0.010000     11   0.17308 0.24231 0.028881

Что видим:
- Строка 5: rel error = 0.173 (17.3%) — самая низкая!
  НО xerror = 0.242 (24.2%) — не улучшилась с строки 4
  
- Строка 4: xerror = 0.242 (24.2%) — МИНИМУМ!
  Это значит: дальнейшие разбиения НЕ улучшают обобщение

ВЫВОД: Выбираем дерево из строки 4 (nsplit=5, CP=0.010256)
        Потому что у него минимальный xerror!


XSTD — ЧТО ЭТО?
---------------
XSTD = стандартное отклонение xerror.

Показывает, насколько "стабильна" оценка xerror.

Если xstd большой → xerror может сильно меняться
Если xstd маленький → xerror стабильный

В нашем примере xstd уменьшается (0.046 → 0.028),
это хорошо — оценка становится стабильнее.


ПОЧЕМУ НЕКОТОРЫЕ ПЕРЕМЕННЫЕ НЕ ИСПОЛЬЗУЮТСЯ?
============================================

После pruning переменная может исчезнуть из дерева, потому что:

1. Низкая предсказательная сила
   - Переменная не помогает разделить классы

2. Высокая корреляция с другой переменной
   - Информация уже захвачена другим признаком

3. Шумовой характер связи
   - Связь случайна и не обобщается

4. Порог cp отсёк ветвь
   - Улучшение не оправдывает усложнение модели


--------------------------------------------------------------------------------
                         ЧАСТЬ 4: ИНТЕРАКТИВНЫЕ ГРАФИКИ
--------------------------------------------------------------------------------

В коде используются интерактивные графики через библиотеку plotly.

1. ROC-КРИВАЯ (plotly)
=======================
- Интерактивный график с возможностью наведения мыши
- Показывает FPR и TPR при наведении
- Отображает AUC прямо в легенде
- Сохраняется в файл "roc_curve.html" для просмотра в браузере
- Открывается автоматически в viewer RStudio

2. CONFUSION MATRIX (heatmap plotly)
====================================
- Интерактивная тепловая карта
- При наведении показывает: Actual, Predicted, Count
- Цветовая шкала: белый → синий → тёмно-синий
- Создаются для train и test данных
- Сохраняются в "confusion_matrix_train.html" и "confusion_matrix_test.html"

3. СРАВНЕНИЕ МОДЕЛЕЙ (bar chart plotly)
=======================================
- Столбчатая диаграмма сравнения accuracy до и после pruning
- Показывает количество переменных в каждой модели
- Сохраняется в "model_comparison.html"

4. ДЕРЕВЬЯ РЕШЕНИЙ (rpart.plot улучшенный)
==========================================
- type = 4 — улучшенный стиль отображения
- extra = 101 — показывает количество наблюдений и процент
- box.palette = "RdYlGn" — цветовая палитра (красный-жёлтый-зелёный)
- branch.lty = 3 — пунктирные ветви
- shadow.col = "gray" — тени для объёма
- nn = TRUE — показывает номера узлов

Все интерактивные графики открываются в viewer RStudio или браузере
и позволяют:
- Наводить мышь для детальной информации
- Увеличивать/уменьшать масштаб
- Сохранять как изображение


--------------------------------------------------------------------------------
                         ЧАСТЬ 5: КРАТКОЕ ОПИСАНИЕ КОДА
--------------------------------------------------------------------------------

library(rpart)        # Пакет для построения деревьев решений
library(rpart.plot)   # Визуализация деревьев
library(ROCR)         # ROC-кривые и AUC

data <- read.csv("survey.csv")
train <- data[1:600, ]    # Обучающая выборка
test <- data[601:750, ]   # Тестовая выборка

tree_info <- rpart(MYDEPV ~ Price + Income + Age, ...)
# Строит дерево с Information Gain, 3-fold CV

printcp(tree_info)    # Таблица CP и используемых переменных
rpart.plot(tree_info) # График дерева

pred_train <- predict(tree_info, train, type = "class")
# Предсказания классов для обучающих данных

conf_train <- table(Actual = train$MYDEPV, Predicted = pred_train)
# Confusion matrix: реальные vs предсказанные классы

resub_error <- 1 - sum(diag(conf_train)) / sum(conf_train)
# Resubstitution error = 1 - accuracy

pred_prob <- predict(tree_info, train, type = "prob")[,2]
# Вероятности класса 1 (второй столбец)

pred_obj <- prediction(pred_prob, train$MYDEPV)
perf <- performance(pred_obj, "tpr", "fpr")
plot(perf)            # ROC-кривая
auc <- performance(pred_obj, "auc")@y.values[[1]]
# AUC из объекта performance

pred_test <- predict(tree_info, test, type = "class")
conf_test <- table(Actual = test$MYDEPV, Predicted = pred_test)
accuracy_test <- sum(diag(conf_test)) / sum(conf_test)
# Точность на тестовых данных

tree_gini <- rpart(..., parms = list(split = "gini"))
# Дерево с Gini вместо Information Gain

best_cp <- tree_gini$cptable[which.min(tree_gini$cptable[,"xerror"]), "CP"]
# CP с минимальным cross-validation error

tree_pruned <- prune(tree_gini, cp = best_cp)
# Обрезка дерева до оптимального размера


--------------------------------------------------------------------------------
                         ЧАСТЬ 6: РАЗБОР ВЫВОДА КОДА
--------------------------------------------------------------------------------

ПУНКТ (a) — ВЫВОД printcp(tree_info)
=====================================

Classification tree:
rpart(formula = MYDEPV ~ Price + Income + Age, data = train, 
    method = "class", parms = list(split = "information"), 
    control = rpart.control(xval = 3))

Variables actually used in tree construction:
[1] Age    Income Price 

Root node error: 260/600 = 0.43333

n= 600 

        CP nsplit rel error  xerror     xstd
1 0.692308      0   1.00000 1.00000 0.046685
2 0.025000      1   0.30769 0.31154 0.032194
3 0.011538      3   0.25769 0.29231 0.031335
4 0.010256      5   0.23462 0.24231 0.028881
5 0.010000     11   0.17308 0.24231 0.028881

РАЗБОР:
-------
1. "Variables actually used" — какие признаки реально использованы
   Ответ: Age, Income, Price — ВСЕ ТРИ!p
   
2. "Root node error: 260/600 = 0.43333"
   - В корне дерева (до разбиений) 260 ошибок из 600 наблюдений
   - Это значит: если просто предсказывать самый частый класс,
     ошибка будет 43.3%
   - 260 — это количество наблюдений минорного класса (класс 1)
   
3. Таблица CP (Complexity Parameter):
   
   Что означают столбцы:
   - CP — параметр сложности (штраф за каждое разбиение)
   - nsplit — количество разбиений (сколько раз дерево разделило данные)
   - rel error — ошибка на ОБУЧАЮЩИХ данных (может быть занижена!)
   - xerror — ошибка КРОСС-ВАЛИДАЦИИ (честная оценка на новых данных)
   - xstd — стандартное отклонение xerror (стабильность оценки)
   
   Строка 1: CP=0.692308, nsplit=0
   - nsplit=0 — это корень, ещё нет разбиений
   - rel error=1.0 — ошибка 100% (базовая, до обучения)
   - xerror=1.0 — CV ошибка 100% (через кросс-валидацию)
   
   Строка 2: CP=0.025000, nsplit=1
   - После первого разбиения
   - rel error=0.30769 — ошибка упала до 30.8% (на train данных)
   - xerror=0.31154 — CV ошибка 31.2% (на новых данных)
   - Видим: xerror чуть выше rel error — это нормально!
   
   Строка 3: CP=0.011538, nsplit=3
   - После трёх разбиений
   - rel error=0.25769 — ошибка 25.8% (на train)
   - xerror=0.29231 — CV ошибка 29.2% (на новых данных)
   - Разница растёт: модель начинает переобучаться!
   
   Строка 4: CP=0.010256, nsplit=5
   - После пяти разбиений
   - rel error=0.23462 — ошибка 23.5% (на train)
   - xerror=0.24231 — CV ошибка 24.2% (МИНИМУМ!)
   - Это оптимальное дерево! xerror минимальный.
   
   Строка 5: CP=0.010000, nsplit=11
   - После 11 разбиений (максимальное дерево)
   - rel error=0.17308 — ошибка 17.3% (самая низкая на train)
   - xerror=0.24231 — CV ошибка 24.2% (НЕ улучшилась!)
   - Видим: rel error упала, но xerror осталась той же
   - Это признак OVERFITTING! Модель запоминает train, но не обобщает
   
   ВЫВОД: 
   - Минимальный xerror = 0.24231 при nsplit=5 (строка 4)
   - Дальнейшие разбиения НЕ улучшают обобщение
   - Выбираем дерево из строки 4 для pruning!


ПУНКТ (b) — CONFUSION MATRIX (train)
====================================

      Predicted
Actual   0   1
     0 314  26
     1  19 241

РАЗБОР:
-------
Это таблица 2x2, где:
- Строки = реальные классы (Actual)
- Столбцы = предсказанные классы (Predicted)

Клетка [0,0] = 314 — True Negative (TN)
  Реально 0, предсказали 0 — ПРАВИЛЬНО

Клетка [0,1] = 26 — False Positive (FP)
  Реально 0, предсказали 1 — ОШИБКА (ложная тревога)

Клетка [1,0] = 19 — False Negative (FN)
  Реально 1, предсказали 0 — ОШИБКА (пропуск)

Клетка [1,1] = 241 — True Positive (TP)
  Реально 1, предсказали 1 — ПРАВИЛЬНО

ИТОГО:
- Всего наблюдений класса 0: 314 + 26 = 340
- Всего наблюдений класса 1: 19 + 241 = 260
- Правильных ответов: 314 + 241 = 555
- Ошибок: 26 + 19 = 45
- Accuracy = 555/600 = 0.925 (92.5%)

Какой класс лучше классифицируется?
- Класс 0: 314 правильных из 340 = 92.4%
- Класс 1: 241 правильный из 260 = 92.7%
Оба класса классифицируются примерно одинаково хорошо!


ПУНКТ (c) — RESUBSTITUTION ERROR
=================================

[1] 0.075

РАЗБОР:
-------
Resubstitution Error = 0.075 = 7.5%

Это ошибка на ОБУЧАЮЩИХ данных (тех же, на которых училась модель).

Проверка: 1 - accuracy = 1 - 0.925 = 0.075 ✓

Почему это плохой показатель?
- Модель уже "видела" эти данные
- Может быть overfitting (переобучение)
- Реальная ошибка на новых данных будет выше


ПУНКТ (d) — AUC
===============

[1] 0.9720645

РАЗБОР:
-------
AUC = 0.972 — это ОТЛИЧНЫЙ результат!

Интерпретация:
- AUC = 0.5 — случайный классификатор (как подбрасывание монетки)
- AUC = 0.7-0.8 — приемлемо
- AUC = 0.8-0.9 — хорошо
- AUC = 0.9-1.0 — отлично
- AUC = 0.972 — модель ОЧЕНЬ хорошо разделяет классы

НО! Это AUC на ОБУЧАЮЩИХ данных. На тестовых данных AUC будет ниже.


ПУНКТ (e) — ТЕСТОВАЯ ТОЧНОСТЬ
==============================

      Predicted
Actual  0  1
     0 76 10
     1  6 58

[1] 0.8933333

РАЗБОР:
-------
Confusion Matrix на тестовых данных:
- TN = 76, FP = 10, FN = 6, TP = 58
- Всего тестовых наблюдений: 76 + 10 + 6 + 58 = 150
- Правильных: 76 + 58 = 134
- Accuracy = 134/150 = 0.893 = 89.3%

СРАВНЕНИЕ:
- Train accuracy = 92.5%
- Test accuracy = 89.3%
- Разница = 3.2%

Это признак ЛЁГКОГО OVERFITTING!
Модель чуть лучше работает на данных, которые видела при обучении,
чем на новых данных. Но разница небольшая, модель всё ещё хорошая.


ПУНКТ (f) — GINI ДЕРЕВО
========================

Classification tree:
rpart(formula = MYDEPV ~ Price + Income + Age, data = train, 
    method = "class", parms = list(split = "gini"), 
    control = rpart.control(xval = 3))

Variables actually used in tree construction:
[1] Age    Income Price 

Root node error: 260/600 = 0.43333

n= 600 

        CP nsplit rel error  xerror     xstd
1 0.692308      0   1.00000 1.00000 0.046685
2 0.025000      1   0.30769 0.31154 0.032194
3 0.011538      3   0.25769 0.25769 0.029672
4 0.010256      5   0.23462 0.25769 0.029672
5 0.010000     11   0.17308 0.25769 0.029672

РАЗБОР:
-------
Сравнение с Information Gain:

1. Используемые переменные: те же (Age, Income, Price)

2. Root node error: тот же (260/600 = 0.43333)

3. Таблица CP:
   - Первые 2 строки идентичны
   - Строка 3: xerror = 0.25769 (у Gini) vs 0.29231 (у Information Gain)
   - Строка 4: xerror = 0.25769 (у Gini) vs 0.24231 (у Information Gain)
   - Строка 5: xerror = 0.25769 (у Gini) vs 0.24231 (у Information Gain)

ВЫВОД: 
- У Gini минимальный xerror = 0.25769 (при nsplit=3,4,5)
- У Information Gain минимальный xerror = 0.24231 (при nsplit=5)
- Information Gain дал чуть лучший результат на CV!


ПУНКТ (g) — PRUNING
===================

Classification tree:
rpart(formula = MYDEPV ~ Price + Income + Age, data = train, 
    method = "class", parms = list(split = "gini"), 
    control = rpart.control(xval = 3))

Variables actually used in tree construction:
[1] Income Price 

Root node error: 260/600 = 0.43333

n= 600 

        CP nsplit rel error  xerror     xstd
1 0.692308      0   1.00000 1.00000 0.046685
2 0.025000      1   0.30769 0.31154 0.032194
3 0.011538      3   0.25769 0.25769 0.029672

РАЗБОР:
-------
ДО PRUNING:
- Variables used: Age, Income, Price (3 переменные)
- Минимальный xerror = 0.25769 при nsplit=3,4,5
- best_cp = 0.011538 (соответствует минимальному xerror)

ПОСЛЕ PRUNING:
- Variables used: Income, Price (только 2 переменные!)
- Age ВЫПАЛА из дерева!
- nsplit уменьшился до 3 (было 11)
- xerror остался 0.25769 (не ухудшился!)

ПОЧЕМУ Age НЕ ИСПОЛЬЗУЕТСЯ?
1. Её вклад в предсказание не оправдывает усложнение модели
2. Информация, которую даёт Age, уже частично захвачена Income или Price
3. Связь Age с MYDEPV может быть слабой или шумовой
4. Pruning удалил ветви, где использовалась Age, т.к. они не улучшали
   cross-validation error


ПУНКТ (h) — СРАВНЕНИЕ ДО И ПОСЛЕ PRUNING
=========================================

ДО PRUNING (tree_gini):
      Predicted
Actual   0   1
     0 314  26
     1  19 241

[1] 0.925

ПОСЛЕ PRUNING (tree_pruned):
      Predicted
Actual   0   1
     0 327  13
     1  54 206

[1] 0.8883333

РАЗБОР:
-------
ДО PRUNING:
- Accuracy = 92.5%
- TN=314, FP=26, FN=19, TP=241
- Ошибок: 26 + 19 = 45

ПОСЛЕ PRUNING:
- Accuracy = 88.8%
- TN=327, FP=13, FN=54, TP=206
- Ошибок: 13 + 54 = 67

СРАВНЕНИЕ:
- Точность упала: 92.5% → 88.8% (на 3.7%)
- Но модель стала ПРОЩЕ: 3 переменные → 2 переменные
- Меньше разбиений: 11 → 3

ДЕТАЛЬНЫЙ АНАЛИЗ:
1. Класс 0 стал классифицироваться ЛУЧШЕ:
   - До: 314/340 = 92.4%
   - После: 327/340 = 96.2% ✓

2. Класс 1 стал классифицироваться ХУЖЕ:
   - До: 241/260 = 92.7%
   - После: 206/260 = 79.2% ✗

3. False Negatives выросли: 19 → 54
   - Модель стала чаще пропускать класс 1

ВЫВОД:
Pruning упростил модель, но немного ухудшил точность на обучающих данных.
НО! На новых данных (test) pruned модель может работать НЕ ХУЖЕ, т.к.:
- Меньше overfitting
- Лучше обобщение
- Проще интерпретация


--------------------------------------------------------------------------------
                         ЧАСТЬ 7: ОБЩИЙ АНАЛИЗ И ВЫВОДЫ
--------------------------------------------------------------------------------

ЧТО МЫ ДЕЛАЕМ И ЗАЧЕМ?
======================

Контекст задачи:
У нас есть данные опроса (survey.csv) с переменными:
- MYDEPV — зависимая переменная (0 или 1), что-то типа "купит/не купит"
- Price — цена (10, 20, 30)
- Income — доход
- Age — возраст

Цель: построить модель, которая предсказывает MYDEPV на основе остальных
переменных.


КЛЮЧЕВЫЕ ВЫВОДЫ ИЗ РЕЗУЛЬТАТОВ
===============================

1. ВСЕ ПЕРЕМЕННЫЕ ИНФОРМАТИВНЫ (до pruning)
   - Age, Income, Price — все три использованы в дереве
   - Это значит, что каждая переменная вносит вклад в предсказание

2. МОДЕЛЬ ХОРОШО РАБОТАЕТ
   - Train accuracy = 92.5%
   - Test accuracy = 89.3%
   - AUC = 0.972 (отлично!)
   - Оба класса классифицируются примерно одинаково хорошо

3. ЕСТЬ ЛЁГКИЙ OVERFITTING
   - Train accuracy (92.5%) > Test accuracy (89.3%)
   - Разница 3.2% — небольшая, но есть
   - Это нормально для деревьев решений

4. INFORMATION GAIN ЛУЧШЕ GINI (в данном случае)
   - Information Gain: минимальный xerror = 0.24231
   - Gini: минимальный xerror = 0.25769
   - Information Gain дал чуть лучший результат на CV

5. PRUNING УПРОЩАЕТ МОДЕЛЬ
   - После pruning: только Income и Price (Age выпала)
   - Точность упала на 3.7%, но модель стала проще
   - Меньше риск overfitting на новых данных

6. PRUNING ИЗМЕНИЛ БАЛАНС КЛАССОВ
   - Класс 0 стал классифицироваться лучше (96.2% vs 92.4%)
   - Класс 1 стал классифицироваться хуже (79.2% vs 92.7%)
   - Это trade-off: простота vs точность для каждого класса


ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ
==========================

1. Для продакшена лучше использовать pruned модель:
   - Проще интерпретировать
   - Меньше риск overfitting
   - Легче объяснить бизнесу

2. Если важна точность класса 1:
   - Использовать модель до pruning
   - Или настроить веса классов

3. Information Gain vs Gini:
   - В данном случае Information Gain лучше
   - Но разница небольшая
   - На практике можно использовать любой

4. Resubstitution error НЕ использовать для оценки:
   - Всегда проверять на test данных
   - Или использовать cross-validation error


--------------------------------------------------------------------------------
                         ШПАРГАЛКА: CP, XERROR, CV
--------------------------------------------------------------------------------

CP (Complexity Parameter)
-------------------------
- Штраф за сложность дерева
- Чем больше CP, тем проще дерево
- Выбираем CP с минимальным xerror

CV (Cross-Validation)
---------------------
- Способ проверить модель на новых данных
- 3-fold CV = делим данные на 3 части, тестируем 3 раза
- Показывает реальную производительность (без overfitting)

XERROR (Cross-Validation Error)
--------------------------------
- Ошибка через кросс-валидацию
- Более честная оценка, чем rel error
- Выбираем дерево с МИНИМАЛЬНЫМ xerror!

REL ERROR vs XERROR
-------------------
- rel error — ошибка на обучающих данных (может быть занижена)
- xerror — ошибка на новых данных через CV (честная оценка)
- Если rel error << xerror → OVERFITTING!

КАК ЧИТАТЬ ТАБЛИЦУ printcp()
-----------------------------
1. Ищем строку с минимальным xerror
2. Берём CP из этой строки
3. Используем для pruning: prune(tree, cp = best_cp)


--------------------------------------------------------------------------------
                              ПОЛЕЗНЫЕ КОМАНДЫ
--------------------------------------------------------------------------------

printcp(tree)           # Таблица CP
summary(tree)           # Подробная информация
rpart.plot(tree)        # Визуализация
predict(tree, data, type="class")   # Предсказания классов
predict(tree, data, type="prob")    # Вероятности
prune(tree, cp=0.01)    # Обрезка до заданного CP


================================================================================

