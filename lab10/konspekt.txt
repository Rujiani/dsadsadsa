================================================================================
                    КОНСПЕКТ: ВРЕМЕННЫЕ РЯДЫ (Time Series)
                              Лабораторная работа 10
================================================================================

--------------------------------------------------------------------------------
                         ЧАСТЬ 1: ТЕОРЕТИЧЕСКИЕ ОСНОВЫ
--------------------------------------------------------------------------------

ЧТО ТАКОЕ ВРЕМЕННОЙ РЯД?
=========================

Временной ряд — это последовательность наблюдений, записанных через равные 
промежутки времени. Представь график температуры каждый день или курс акций 
каждый час — это и есть временные ряды.

Обозначение: x1, x2, x3, ... , xn  или  xt, где t = 1, 2, 3, ...

В нашей задаче: данные Johnson & Johnson — квартальные доходы на акцию (EPS)
за 21 год (1960-1980), всего 84 наблюдения (4 квартала × 21 год).


ОСНОВНЫЕ КОМПОНЕНТЫ ВРЕМЕННОГО РЯДА
====================================

1. ТРЕНД (Trend) — долгосрочное направление изменения данных
   - Растущий тренд: данные в среднем увеличиваются со временем
   - Падающий тренд: данные в среднем уменьшаются
   - В данных J&J виден чёткий растущий тренд (EPS вырос с 0.7 до 16)

2. СЕЗОННОСТЬ (Seasonality) — повторяющиеся паттерны с фиксированным периодом
   - В квартальных данных период = 4 (повторение каждый год)
   - В J&J видна сезонность: 4-й квартал обычно выше остальных
   - Сезонность повторяется регулярно: Q1, Q2, Q3, Q4, Q1, Q2, ...

3. СЛУЧАЙНЫЙ ШУМ (Noise/Error) — случайные колебания
   - Непредсказуемые случайные изменения
   - Не связаны с трендом или сезонностью


СТАЦИОНАРНОСТЬ
==============

Ряд называется СТАЦИОНАРНЫМ, если:
- Среднее значение НЕ меняется со временем (нет тренда)
- Дисперсия (разброс) НЕ меняется со временем
- Автокорреляция зависит ТОЛЬКО от лага, а не от времени

ПОЧЕМУ ЭТО ВАЖНО?
Модели ARIMA работают ТОЛЬКО со стационарными рядами!
Если ряд нестационарный — его нужно преобразовать.

Пример:
- Нестационарный: EPS растёт от 1 до 16 (есть тренд)
- Стационарный: разности логарифмов колеблются около нуля (нет тренда)


ПРЕОБРАЗОВАНИЯ ДЛЯ СТАЦИОНАРНОСТИ
==================================

1. ДИФФЕРЕНЦИРОВАНИЕ (Differencing)
   --------------------------------
   Вместо xt берём разность: yt = xt - xt-1
   
   Зачем: УБИРАЕТ ТРЕНД
   
   Как работает:
   Если ряд постоянно растёт (xt = 5, 10, 15, 20, ...),
   то после дифференцирования получим: (10-5=5, 15-10=5, 20-15=5, ...)
   — ряд становится стабильным около константы!
   
   В R: diff(x) — считает разности
   Было 84 значения → стало 83 (первое значение теряется)

2. ЛОГАРИФМИРОВАНИЕ
   -----------------
   Вместо xt берём: yt = log(xt) или log10(xt)
   
   Зачем: СТАБИЛИЗИРУЕТ ДИСПЕРСИЮ
   
   Проблема (гетероскедастичность):
   - Когда значения маленькие (например 0.5), колебания ±0.1 = 20%
   - Когда значения большие (например 15), колебания ±0.1 = менее 1%
   - Это разная дисперсия в разных частях ряда!
   
   Логарифм "сжимает" большие значения и "растягивает" маленькие,
   делая относительные колебания примерно одинаковыми.
   
   Пример:
   - Было: 1±0.5 и 15±5 (разная дисперсия)
   - Стало: log(1)±log(1.5) и log(15)±log(20) (примерно одинаковая)

3. КОМБИНАЦИЯ: сначала log, потом diff
   ------------------------------------
   yt = log(xt) - log(xt-1) = log(xt/xt-1)
   
   Это даёт логарифм ОТНОШЕНИЯ соседних значений ≈ относительное изменение
   
   Результат:
   - Тренд убран (через diff)
   - Дисперсия стабилизирована (через log)
   - Ряд становится стационарным!


ACF — АВТОКОРРЕЛЯЦИОННАЯ ФУНКЦИЯ
=================================

ACF(k) показывает корреляцию между xt и xt-k (значения с разницей в k шагов).

Корреляция — число от -1 до +1:
- +1: идеальная положительная связь (одно растёт → другое растёт)
- -1: идеальная отрицательная связь (одно растёт → другое падает)
- 0: нет линейной связи

Формула корреляции:
r(X,Y) = Σ(xi - x̄)(yi - ȳ) / √[Σ(xi - x̄)² × Σ(yi - ȳ)²]

Для ACF:
ACF(k) = Σ(xt - x̄)(xt-k - x̄) / Σ(xt - x̄)²

Интерпретация графика ACF:
- Столбики показывают корреляцию на каждом лаге
- Пунктирные линии — границы значимости
- Если столбик ВЫХОДИТ за пунктир — корреляция значима!

В R: acf(x) строит график ACF


ПОЧЕМУ ACF(0) = 1? (Задание 4.10)
==================================

ACF(0) — это корреляция ряда с САМИМ СОБОЙ (лаг = 0, то есть xt с xt).

Подставим в формулу: X = Y = наш ряд

ACF(0) = Σ(xt - x̄)(xt - x̄) / √[Σ(xt - x̄)² × Σ(xt - x̄)²]
       = Σ(xt - x̄)² / √[Σ(xt - x̄)²]²
       = Σ(xt - x̄)² / Σ(xt - x̄)²
       = 1

Вывод: Любая величина идеально коррелирует сама с собой → корреляция = 1.


PACF — ЧАСТНАЯ АВТОКОРРЕЛЯЦИОННАЯ ФУНКЦИЯ
=========================================

PACF(k) показывает корреляцию между xt и xt-k, ИСКЛЮЧАЯ влияние промежуточных
значений (xt-1, xt-2, ..., xt-k+1).

Пример:
Допустим x1 влияет на x2, а x2 влияет на x3.
Тогда x1 КОСВЕННО связан с x3 через x2.
- ACF(2) покажет эту косвенную связь (x1→x2→x3)
- PACF(2) покажет ТОЛЬКО прямую связь x1→x3 (убрав влияние x2)

В R: pacf(x) строит график PACF


МОДЕЛИ ARIMA
============

ARIMA — это модель, которая помогает прогнозировать значения временного ряда на основе его прошлых значений.

Простыми словами:
- Сначала она "убирает" тренды и сезонность (делает ряд более стабильным с помощью дифференцирования).
- Дальше использует две части:
  - AR (AutoRegressive) — учитывает, что текущее значение может зависеть от предыдущих (как будто "помнит" прошлое).
  - MA (Moving Average) — учитывает ошибки предсказаний в прошлом, чтобы скорректировать новые прогнозы.
- Параметры (p, d, q):
  - p — сколько прошлых значений брать в расчёт (AR)
  - d — сколько раз делать разности (дифференцировать)
  - q — сколько прошлых ошибок учитывать (MA)

Итог: ARIMA автоматически объединяет эти методы, чтобы лучше понять структуру ряда и предсказывать будущее.

Параметры:
- p — порядок авторегрессии (AR)
- d — порядок дифференцирования (I — Integrated)
- q — порядок скользящего среднего (MA)

Как читать: ARIMA(1, 1, 1) означает:
1. Берём diff(x) — одно дифференцирование (d=1)
2. К результату применяем ARMA(1,1) — AR(1) + MA(1)


AR(p) — АВТОРЕГРЕССИЯ
======================

Идея: текущее значение зависит от p предыдущих значений.

Формулы:
- AR(1): xt = φ1×xt-1 + εt
- AR(2): xt = φ1×xt-1 + φ2×xt-2 + εt
- AR(p): xt = φ1×xt-1 + φ2×xt-2 + ... + φp×xt-p + εt

где:
- εt — случайный шум (белый шум)
- φ1, φ2, ... — коэффициенты модели

Как распознать AR(p) по графикам:
- ACF: медленно затухает (экспоненциально или синусоидально)
- PACF: РЕЗКО обрывается после лага p (значимы только первые p значений)

Паттерн из задания 4.11:
- AR(1): PACF имеет 1 значимый пик
- AR(2): PACF имеет 2 значимых пика
- AR(3): PACF имеет 3 значимых пика
- AR(4): PACF имеет 4 значимых пика

ЗАКОНОМЕРНОСТЬ: число значимых пиков PACF = порядок p модели AR


MA(q) — СКОЛЬЗЯЩЕЕ СРЕДНЕЕ
===========================

Идея: текущее значение зависит от q предыдущих ОШИБОК.

Формулы:
- MA(1): xt = εt + θ1×εt-1
- MA(2): xt = εt + θ1×εt-1 + θ2×εt-2
- MA(q): xt = εt + θ1×εt-1 + ... + θq×εt-q

где:
- εt — текущая ошибка (белый шум)
- θ1, θ2, ... — коэффициенты модели

Как распознать MA(q) по графикам:
- ACF: РЕЗКО обрывается после лага q
- PACF: медленно затухает

Паттерн из задания 4.12:
- MA(1): ACF имеет 1 значимый пик
- MA(2): ACF имеет 2 значимых пика
- MA(3): ACF имеет 3 значимых пика
- MA(4): ACF имеет 4 значимых пика

ЗАКОНОМЕРНОСТЬ: число значимых пиков ACF = порядок q модели MA

Это ПРОТИВОПОЛОЖНО AR моделям!


ARMA(p,q) — КОМБИНАЦИЯ
=======================

ARMA(p,q) сочетает авторегрессию и скользящее среднее:

xt = φ1×xt-1 + ... + φp×xt-p + εt + θ1×εt-1 + ... + θq×εt-q

Как распознать:
- Оба графика (ACF и PACF) затухают
- Подбираем p и q по AIC (информационный критерий)


СЕЗОННАЯ ARIMA — SARIMA
========================

Обозначение: ARIMA(p,d,q) × (P,D,Q)[s]

Где:
- (p,d,q) — обычная ARIMA (несезонная часть)
- (P,D,Q)[s] — сезонная компонента с периодом s

Для квартальных данных: s = 4 (4 квартала в году)

Пример: ARIMA(0,1,1) × (0,1,1)[4] означает:
- Обычная часть: d=1 (одно дифференцирование), q=1 (MA(1))
- Сезонная часть: D=1 (сезонное дифференцирование), Q=1 (сезонная MA(1))

Как распознать:
- Пики на лагах 4, 8, 12, ... (кратные периоду s)
- Нужно добавить сезонную компоненту!


AIC — ИНФОРМАЦИОННЫЙ КРИТЕРИЙ АКАИКЕ
====================================

AIC = 2k - 2ln(L)

где:
- k — число параметров модели
- L — правдоподобие (likelihood) — насколько хорошо модель объясняет данные

Чем МЕНЬШЕ AIC, тем ЛУЧШЕ модель!

Как работает:
AIC штрафует за сложность: добавление лишних параметров увеличивает k,
что увеличивает AIC. Модель должна быть:
- Достаточно простой (не переобучаться)
- Но хорошо объяснять данные (высокое L)

Пример сравнения моделей:
- Модель 1: AIC = -282.53 ← лучше!
- Модель 2: AIC = -277.80
- Модель 3: AIC = -280.55
- Модель 4: AIC = -280.91

Выбираем модель с минимальным AIC!


ПОЧЕМУ ln И log10 ДАЮТ ОДИНАКОВЫЙ РЕЗУЛЬТАТ? (Задание 4.9)
===========================================================

log10(x) = ln(x) / ln(10) ≈ ln(x) / 2.303

То есть log10(x) = k × ln(x), где k = 1/ln(10) ≈ 0.434

Когда мы берём РАЗНОСТЬ:
log10(xt) - log10(xt-1) = k×ln(xt) - k×ln(xt-1) = k × [ln(xt) - ln(xt-1)]

Это просто МАСШТАБИРОВАНИЕ на константу k!

Для анализа временных рядов важна СТРУКТУРА корреляций и паттернов,
а не конкретные числовые значения. Умножение на константу НЕ меняет:
- Форму ACF и PACF
- Выбор модели ARIMA
- Качество предсказаний (после обратного преобразования)

Вывод: можно использовать любой логарифм, результат будет ЭКВИВАЛЕНТЕН!


--------------------------------------------------------------------------------
                         ЧАСТЬ 2: РАЗБОР КОДА
--------------------------------------------------------------------------------

ЗАГРУЗКА ДАННЫХ
===============

jj <- scan("jj.dat")
# scan() читает числа из файла в вектор

jj_ts <- ts(jj, start = c(1960, 1), frequency = 4)
# ts() создаёт объект временного ряда
# start = c(1960, 1) — начало: 1960 год, 1-й квартал
# frequency = 4 — 4 наблюдения в год (квартальные данные)


ПОСТРОЕНИЕ ГРАФИКОВ
===================

par(mfrow = c(2, 1))
# Разбивает окно на 2 строки и 1 столбец для нескольких графиков

plot(jj_ts, ...)
# Строит график временного ряда


ДИФФЕРЕНЦИРОВАНИЕ
=================

diff_jj <- diff(jj_ts)
# diff() вычисляет xt - xt-1 для всех t > 1
# Было 84 значения → стало 83 (первое значение теряется)


ЛОГАРИФМИРОВАНИЕ
================

log_jj <- log10(jj_ts)
# Поэлементный логарифм по основанию 10

diff_log_jj <- diff(log_jj)
# Разность логарифмов = log(xt/xt-1)


ACF И PACF
==========

acf(diff_log_jj, main = "...", lag.max = 20)
pacf(diff_log_jj, main = "...", lag.max = 20)
# lag.max — максимальный лаг для отображения
# Пунктирные линии на графике — границы значимости
# Если столбик выходит за пунктир — корреляция значима!


ПОДГОНКА ARIMA
==============

model1 <- arima(log_jj, order = c(0, 1, 1), 
                seasonal = list(order = c(0, 1, 1), period = 4))
# order = c(p, d, q) — параметры ARIMA
# seasonal = list(order = c(P, D, Q), period = s) — сезонная часть

AIC(model1)
# Возвращает значение AIC для сравнения моделей


СИМУЛЯЦИЯ
=========

arima.sim(n = 10000, list(ar = c(0.9, -0.5, 0.2, -0.3)))
# n — количество точек
# list(ar = ...) — коэффициенты AR модели
# list(ma = ...) — коэффициенты MA модели


--------------------------------------------------------------------------------
                         ЧАСТЬ 3: РАЗБОР ВЫВОДА КОДА
--------------------------------------------------------------------------------

ВЫВОД scan("jj.dat")
====================

"Read 84 items"

Что это:
scan() читает числа из файла и выводит сообщение о количестве прочитанных 
значений. В файле jj.dat 84 значения (21 год × 4 квартала).


ВЫВОД cat() — AIC МОДЕЛЕЙ
==========================

AIC моделей:
ARIMA(0,1,1)x(0,1,1)[4]: -282.5299 
ARIMA(1,1,0)x(0,1,1)[4]: -277.7962 
ARIMA(1,1,1)x(0,1,1)[4]: -280.5477 
ARIMA(0,1,1)x(1,1,1)[4]: -280.9088 

Что это:
Функция cat() выводит текст и значения AIC для каждой модели.
AIC() извлекает значение AIC из объекта модели.

Откуда берутся числа:
- AIC рассчитывается функцией arima() при подгонке модели
- Формула: AIC = 2k - 2ln(L), где k — число параметров, L — правдоподобие
- Меньшее значение = лучшая модель

Интерпретация:
- ARIMA(0,1,1)×(0,1,1)[4] имеет AIC = -282.53 — НАИМЕНЬШЕЕ значение
- Значит эта модель ЛУЧШАЯ из четырёх


ВЫВОД print(best_model) — ДЕТАЛЬНАЯ ИНФОРМАЦИЯ О МОДЕЛИ
=======================================================

Call:
arima(x = log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))

Coefficients:
          ma1     sma1
      -0.6809  -0.3146
s.e.   0.0982   0.1070

sigma^2 estimated as 0.001496:  log likelihood = 144.26,  aic = -282.53

РАЗБОР ПО СТРОКАМ:
------------------

1. Строка "Call:" — показывает какую команду использовали
   - x = log_jj — какие данные использовались (логарифм EPS)
   - order = c(0, 1, 1) — параметры несезонной части: p=0, d=1, q=1
   - seasonal = list(order = c(0, 1, 1), period = 4) — сезонная часть: P=0, D=1, Q=1, период=4

2. Строка "Coefficients:" — ОЦЕНЕННЫЕ КОЭФФИЦИЕНТЫ МОДЕЛИ
   
   ma1 = -0.6809 — коэффициент MA(1) компоненты (несезонной)
   Что это: в модели MA(1) текущее значение зависит от предыдущей ошибки 
            с весом -0.6809. Отрицательное значение означает отрицательную корреляцию.
   
   sma1 = -0.3146 — коэффициент сезонной MA(1) компоненты
   Что это: влияние ошибки с лагом 4 (сезонный лаг) с весом -0.3146
   
   s.e. = standard error (стандартная ошибка)
   - ma1 s.e. = 0.0982 — стандартная ошибка коэффициента ma1
   - sma1 s.e. = 0.1070 — стандартная ошибка коэффициента sma1
   
   Что это: мера точности оценки коэффициента. Чем меньше s.e., тем точнее оценка.
   
   Проверка значимости:
   Если |коэффициент| / s.e. > 2, то коэффициент значим.
   - |-0.6809| / 0.0982 ≈ 6.93 > 2 → ma1 ЗНАЧИМ
   - |-0.3146| / 0.1070 ≈ 2.94 > 2 → sma1 ЗНАЧИМ

3. Строка "sigma^2 estimated as ..." — ОЦЕНКА ДИСПЕРСИИ ОШИБОК
   sigma^2 = 0.001496 — оценка дисперсии случайных ошибок (шума)
   
   Что это: средний квадрат разности между реальными значениями и предсказаниями модели
   Чем меньше, тем лучше модель объясняет данные.
   В нашем случае 0.001496 — ОЧЕНЬ мало (хорошо!)

4. Строка "log likelihood = ..." — ЛОГАРИФМ ПРАВДОПОДОБИЯ
   log likelihood = 144.26 — натуральный логарифм функции правдоподобия
   
   Что это: мера того, насколько хорошо модель объясняет данные
   Чем БОЛЬШЕ log likelihood, тем лучше модель
   Используется для расчёта AIC

5. Строка "aic = ..." — ИНФОРМАЦИОННЫЙ КРИТЕРИЙ АКАИКЕ
   aic = -282.53 — то же самое, что выводилось отдельно
   Используется для сравнения моделей


ВЫВОД tsdiag(best_model) — ДИАГНОСТИКА МОДЕЛИ
=============================================

tsdiag() создаёт 3 графика:

График 1: Остатки (Residuals)
- Показывает разности между реальными значениями и предсказаниями модели
- Должны выглядеть как случайный шум (белый шум)
- НЕ должно быть явных трендов или паттернов
- Если есть тренд/паттерн — модель плохая

График 2: ACF остатков (Autocorrelations)
- Показывает автокорреляцию остатков
- Если модель хорошая, остатки НЕ должны коррелировать между собой
- Все столбики должны быть ВНУТРИ пунктирных линий (не значимы)
- Если есть значимые пики — модель пропустила какую-то зависимость

График 3: p-values теста Льюнг-Бокса (Ljung-Box Test)
- Статистический тест на отсутствие автокорреляции в остатках
- Нулевая гипотеза: остатки — белый шум (нет автокорреляции)
- p-value > 0.05 → принимаем нулевую гипотезу (остатки хорошие)
- p-value < 0.05 → отклоняем (остатки плохие, есть автокорреляция)
- Все точки должны быть ВЫШЕ линии 0.05


--------------------------------------------------------------------------------
                         ЧАСТЬ 4: АНАЛИЗ РЕЗУЛЬТАТОВ
--------------------------------------------------------------------------------

ЗАДАНИЕ 4.8a: ГРАФИК ИСХОДНОГО РЯДА
====================================

На графике EPS vs время видно:

1. Чёткий растущий ТРЕНД
   - EPS увеличился с ~0.7 до ~16 за 21 год
   - Постоянный рост (не линейный, экспоненциальный)

2. СЕЗОННОСТЬ
   - Повторяющийся паттерн каждый год
   - Пики в определённых кварталах (обычно 4-й квартал выше)

3. Увеличение АМПЛИТУДЫ колебаний со временем
   - Когда EPS был ~1, колебания были ~0.3
   - Когда EPS стал ~15, колебания стали ~5
   - Это ГЕТЕРОСКЕДАСТИЧНОСТЬ (непостоянная дисперсия)

Вывод: ряд НЕСТАЦИОНАРНЫЙ (есть тренд, меняется дисперсия)


ЗАДАНИЕ 4.8b: ПРОСТОЕ ДИФФЕРЕНЦИРОВАНИЕ
========================================

После diff(xt) — вычитания предыдущего значения:

1. Тренд частично убран
   - Ряд колеблется около нуля, а не растёт
   - Среднее примерно постоянно

2. НО дисперсия всё ещё нестабильна
   - В начале колебания ~0.3
   - В конце колебания ~5
   - Это плохо для ARIMA!

Константная дисперсия важна потому что:
- Модель предполагает одинаковый "разброс" ошибок во всех точках
- Если дисперсия разная, предсказания будут неточными
- Статистические тесты дадут неверные результаты

Вывод: простое дифференцирование НЕ достаточно!


ЗАДАНИЕ 4.8c: ЛОГАРИФМИРОВАНИЕ + ДИФФЕРЕНЦИРОВАНИЕ
===================================================

log10(EPS):
- Тренд всё ещё есть, но стал более линейным
- Сезонность сохранилась
- Логарифм сам по себе не убирает тренд

diff(log10(EPS)):
- Тренд УБРАН (через diff)
- Дисперсия стала СТАБИЛЬНОЙ (через log)
- Колебания примерно одинаковы
- Ряд выглядит стационарным!

Вывод: комбинация log + diff эффективно стационаризует ряд.
Это и есть правильное преобразование для наших данных!


ЗАДАНИЕ 4.8d: АНАЛИЗ ACF И PACF
================================

На графиках ACF и PACF разности логарифмов видно:

ACF:
- Значимый пик на лаге 1 (высота ~0.6)
- Значимые пики на лагах 4, 8, 12 (кратные 4 — сезонность!)
- Медленное затухание сезонных пиков

PACF:
- Значимый пик на лаге 1
- Пики на сезонных лагах (4, 8, 12)

Интерпретация:
1. MA(1) компонента (пик на ACF при лаге 1)
2. Сезонная компонента с периодом 4 (пики на лагах 4, 8, 12)

Предлагаемые модели:
- ARIMA(0,1,1)×(0,1,1)[4] — MA(1) + сезонная MA(1) ← классическая "airline model"
- ARIMA(1,1,0)×(0,1,1)[4] — AR(1) + сезонная MA(1)
- ARIMA(1,1,1)×(0,1,1)[4] — смешанная ARMA(1,1) + сезонная MA(1)
- ARIMA(0,1,1)×(1,1,1)[4] — MA(1) + сезонная ARMA(1,1)


ЗАДАНИЕ 4.8e: СРАВНЕНИЕ МОДЕЛЕЙ
================================

По результатам AIC:
- ARIMA(0,1,1)×(0,1,1)[4]: -282.53 ← ЛУЧШАЯ (минимальный AIC)
- ARIMA(0,1,1)×(1,1,1)[4]: -280.91
- ARIMA(1,1,1)×(0,1,1)[4]: -280.55
- ARIMA(1,1,0)×(0,1,1)[4]: -277.80

Лучшая модель: ARIMA(0,1,1)×(0,1,1)[4]
Это классическая "airline model" для сезонных данных!

Проверка диагностики (tsdiag):
- Остатки похожи на белый шум (график 1)
- ACF остатков не имеет значимых пиков (график 2)
- p-values теста Льюнг-Бокса > 0.05 (график 3)
- Модель ХОРОШАЯ!


ЗАДАНИЕ 4.11: ПАТТЕРНЫ AR(p)
=============================

AR(1): 
- PACF — 1 значимый пик
- ACF — медленное экспоненциальное затухание

AR(2):
- PACF — 2 значимых пика
- ACF — затухание (возможно осцилляция)

AR(3):
- PACF — 3 значимых пика
- ACF — сложное затухание

AR(4):
- PACF — 4 значимых пика
- ACF — сложное затухание

ЗАКОНОМЕРНОСТЬ: число значимых пиков PACF = порядок p модели AR


ЗАДАНИЕ 4.12: ПАТТЕРНЫ MA(q)
=============================

MA(1):
- ACF — 1 значимый пик
- PACF — медленное затухание

MA(2):
- ACF — 2 значимых пика
- PACF — затухание

MA(3):
- ACF — 3 значимых пика
- PACF — затухание

MA(4):
- ACF — 4 значимых пика
- PACF — затухание

ЗАКОНОМЕРНОСТЬ: число значимых пиков ACF = порядок q модели MA

Это ЗЕРКАЛЬНО относительно AR моделей!


--------------------------------------------------------------------------------
                         ЧАСТЬ 5: ОБЩИЙ АНАЛИЗ И ВЫВОДЫ
--------------------------------------------------------------------------------

ЧТО МЫ ДЕЛАЕМ И ЗАЧЕМ?
======================

Контекст задачи:
У нас есть данные Johnson & Johnson — квартальные доходы на акцию (EPS)
за 21 год (1960-1980), всего 84 наблюдения.

Цель: построить модель, которая может:
1. Описать структуру временного ряда
2. Предсказать будущие значения EPS
3. Понять закономерности (тренд, сезонность)


КЛЮЧЕВЫЕ ВЫВОДЫ ИЗ РЕЗУЛЬТАТОВ
===============================

1. ИСХОДНЫЙ РЯД НЕСТАЦИОНАРНЫЙ
   - Есть тренд (EPS растёт)
   - Есть сезонность (квартальные паттерны)
   - Непостоянная дисперсия (гетероскедастичность)
   - Нужно преобразовать!

2. ПРЕОБРАЗОВАНИЕ log + diff ЭФФЕКТИВНО
   - Тренд убран (через diff)
   - Дисперсия стабилизирована (через log)
   - Ряд стал стационарным
   - Можно строить ARIMA модель!

3. ЛУЧШАЯ МОДЕЛЬ — ARIMA(0,1,1)×(0,1,1)[4]
   - Минимальный AIC = -282.53
   - Классическая "airline model" для сезонных данных
   - Коэффициенты значимы (|coef|/s.e. > 2)
   - Диагностика хорошая (остатки — белый шум)

4. СЕЗОННОСТЬ ВАЖНА
   - Пики на лагах 4, 8, 12 в ACF/PACF
   - Без сезонной компоненты модель была бы хуже
   - Сезонное дифференцирование необходимо

5. ПАТТЕРНЫ AR И MA РАЗЛИЧАЮТСЯ
   - AR(p): PACF обрывается после лага p, ACF затухает
   - MA(q): ACF обрывается после лага q, PACF затухает
   - Это ЗЕРКАЛЬНО!


ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ
==========================

1. Всегда проверяйте стационарность:
   - График исходного ряда
   - График разностей
   - ACF/PACF

2. Преобразования по порядку:
   - Если есть тренд → дифференцируем (diff)
   - Если дисперсия непостоянна → логарифмируем (log)
   - Если есть сезонность → сезонное дифференцирование

3. Выбор модели:
   - Смотрим на ACF/PACF
   - Предлагаем несколько моделей
   - Сравниваем по AIC (меньше = лучше)
   - Проверяем диагностику (tsdiag)

4. Интерпретация коэффициентов:
   - Проверяем значимость (|coef|/s.e. > 2)
   - Смотрим на знак (положительный/отрицательный)
   - Анализируем сезонные компоненты

5. AIC для сравнения:
   - Всегда сравниваем модели по AIC
   - Меньшее AIC = лучше
   - Но проверяем диагностику тоже!


--------------------------------------------------------------------------------
                         ЧАСТЬ 6: ШПАРГАЛКА
--------------------------------------------------------------------------------

КАК ВЫБРАТЬ МОДЕЛЬ ARIMA?
=========================

Смотрим на ACF и PACF стационарного ряда:

1. ACF резко обрывается после лага q, PACF затухает → MA(q)
2. PACF резко обрывается после лага p, ACF затухает → AR(p)
3. Оба затухают → ARMA(p,q), подбираем по AIC
4. Есть пики на сезонных лагах (4, 8, 12...) → добавляем сезонную компоненту

Если ряд нестационарный:
- Есть тренд → дифференцируем (d = 1 или 2)
- Дисперсия меняется → логарифмируем
- Есть сезонный тренд → сезонное дифференцирование (D = 1)


AR VS MA — КАК РАЗЛИЧИТЬ?
==========================

AR(p):
- PACF обрывается после лага p
- ACF затухает медленно

MA(q):
- ACF обрывается после лага q
- PACF затухает медленно

ЗЕРКАЛЬНО!


ПРЕОБРАЗОВАНИЯ — КОГДА ЧТО?
============================

Тренд есть → diff() (дифференцирование)
Дисперсия непостоянна → log() (логарифмирование)
Сезонность есть → сезонное diff() + сезонная ARIMA

Обычно: log → diff → ARIMA


AIC — КАК ИСПОЛЬЗОВАТЬ?
=======================

1. Подгоняем несколько моделей
2. Сравниваем AIC
3. Выбираем с минимальным AIC
4. НО проверяем диагностику тоже!


ДИАГНОСТИКА МОДЕЛИ
==================

tsdiag() показывает 3 графика:

1. Остатки — должны быть белым шумом (случайные)
2. ACF остатков — не должно быть значимых пиков
3. p-values Льюнг-Бокса — должны быть > 0.05

Если всё ок → модель хорошая!


--------------------------------------------------------------------------------
                         ПОЛЕЗНЫЕ КОМАНДЫ
--------------------------------------------------------------------------------

scan("file.dat")              # Чтение чисел из файла
ts(data, start=c(1960,1), frequency=4)  # Создание временного ряда
diff(x)                       # Дифференцирование
log10(x) или log(x)          # Логарифмирование
acf(x, lag.max=20)           # Автокорреляционная функция
pacf(x, lag.max=20)          # Частная автокорреляционная функция
arima(x, order=c(p,d,q), seasonal=list(order=c(P,D,Q), period=s))  # Подгонка ARIMA
AIC(model)                   # Информационный критерий Акаике
print(model)                 # Вывод информации о модели
tsdiag(model)                # Диагностика модели
arima.sim(n=10000, list(ar=c(...)))  # Симуляция AR модели
arima.sim(n=10000, list(ma=c(...)))  # Симуляция MA модели
plot_ly(...)                 # Интерактивные графики (plotly)


================================================================================
