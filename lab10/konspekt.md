# КОНСПЕКТ: ВРЕМЕННЫЕ РЯДЫ (Time Series)
## Лабораторная работа 10

---

## ЧАСТЬ 1: ТЕОРЕТИЧЕСКИЕ ОСНОВЫ

### ЧТО ТАКОЕ ВРЕМЕННОЙ РЯД?

Временной ряд — это последовательность наблюдений, записанных через равные промежутки времени. Представь график температуры каждый день или курс акций каждый час — это и есть временные ряды.

**Обозначение:** x₁, x₂, x₃, ... , xₙ или xₜ, где t = 1, 2, 3, ...

**В нашей задаче:** данные Johnson & Johnson — квартальные доходы на акцию (EPS) за 21 год (1960-1980), всего 84 наблюдения (4 квартала × 21 год).

### ОСНОВНЫЕ КОМПОНЕНТЫ ВРЕМЕННОГО РЯДА

1. **ТРЕНД (Trend)** — долгосрочное направление изменения данных
   - Растущий тренд: данные в среднем увеличиваются со временем
   - Падающий тренд: данные в среднем уменьшаются
   - В данных J&J виден чёткий растущий тренд (EPS вырос с 0.7 до 16)

2. **СЕЗОННОСТЬ (Seasonality)** — повторяющиеся паттерны с фиксированным периодом
   - В квартальных данных период = 4 (повторение каждый год)
   - В J&J видна сезонность: 4-й квартал обычно выше остальных
   - Сезонность повторяется регулярно: Q1, Q2, Q3, Q4, Q1, Q2, ...

3. **СЛУЧАЙНЫЙ ШУМ (Noise/Error)** — случайные колебания
   - Непредсказуемые случайные изменения
   - Не связаны с трендом или сезонностью

### СТАЦИОНАРНОСТЬ

Ряд называется **СТАЦИОНАРНЫМ**, если:
- Среднее значение **НЕ** меняется со временем (нет тренда)
- Дисперсия (разброс) **НЕ** меняется со временем
- Автокорреляция зависит **ТОЛЬКО** от лага, а не от времени

**ПОЧЕМУ ЭТО ВАЖНО?**  
Модели ARIMA работают **ТОЛЬКО** со стационарными рядами!  
Если ряд нестационарный — его нужно преобразовать.

**Пример:**
- Нестационарный: EPS растёт от 1 до 16 (есть тренд)
- Стационарный: разности логарифмов колеблются около нуля (нет тренда)

### ПРЕОБРАЗОВАНИЯ ДЛЯ СТАЦИОНАРНОСТИ

#### 1. ДИФФЕРЕНЦИРОВАНИЕ (Differencing)

Вместо xₜ берём разность: **yₜ = xₜ - xₜ₋₁**

**Зачем:** УБИРАЕТ ТРЕНД

**Как работает:**  
Если ряд постоянно растёт (xₜ = 5, 10, 15, 20, ...),  
то после дифференцирования получим: (10-5=5, 15-10=5, 20-15=5, ...)  
— ряд становится стабильным около константы!

**В R:** `diff(x)` — считает разности  
Было 84 значения → стало 83 (первое значение теряется)

#### 2. ЛОГАРИФМИРОВАНИЕ

Вместо xₜ берём: **yₜ = log(xₜ)** или **log₁₀(xₜ)**

**Зачем:** СТАБИЛИЗИРУЕТ ДИСПЕРСИЮ

**Проблема (гетероскедастичность):**
- Когда значения маленькие (например 0.5), колебания ±0.1 = 20%
- Когда значения большие (например 15), колебания ±0.1 = менее 1%
- Это разная дисперсия в разных частях ряда!

Логарифм "сжимает" большие значения и "растягивает" маленькие, делая относительные колебания примерно одинаковыми.

**Пример:**
- Было: 1±0.5 и 15±5 (разная дисперсия)
- Стало: log(1)±log(1.5) и log(15)±log(20) (примерно одинаковая)

#### 3. КОМБИНАЦИЯ: сначала log, потом diff

**yₜ = log(xₜ) - log(xₜ₋₁) = log(xₜ/xₜ₋₁)**

Это даёт логарифм **ОТНОШЕНИЯ** соседних значений ≈ относительное изменение

**Результат:**
- Тренд убран (через diff)
- Дисперсия стабилизирована (через log)
- Ряд становится стационарным!

### ACF — АВТОКОРРЕЛЯЦИОННАЯ ФУНКЦИЯ

**ACF(k)** показывает корреляцию между xₜ и xₜ₋ₖ (значения с разницей в k шагов).

**Корреляция** — число от -1 до +1:
- **+1:** идеальная положительная связь (одно растёт → другое растёт)
- **-1:** идеальная отрицательная связь (одно растёт → другое падает)
- **0:** нет линейной связи

**Формула корреляции:**
```
r(X,Y) = Σ(xᵢ - x̄)(yᵢ - ȳ) / √[Σ(xᵢ - x̄)² × Σ(yᵢ - ȳ)²]
```

**Для ACF:**
```
ACF(k) = Σ(xₜ - x̄)(xₜ₋ₖ - x̄) / Σ(xₜ - x̄)²
```

**Интерпретация графика ACF:**
- Столбики показывают корреляцию на каждом лаге
- Пунктирные линии — границы значимости
- Если столбик **ВЫХОДИТ** за пунктир — корреляция значима!

**В R:** `acf(x)` строит график ACF

### ПОЧЕМУ ACF(0) = 1? (Задание 4.10)

**ACF(0)** — это корреляция ряда с **САМИМ СОБОЙ** (лаг = 0, то есть xₜ с xₜ).

Подставим в формулу: X = Y = наш ряд

```
ACF(0) = Σ(xₜ - x̄)(xₜ - x̄) / √[Σ(xₜ - x̄)² × Σ(xₜ - x̄)²]
       = Σ(xₜ - x̄)² / √[Σ(xₜ - x̄)²]²
       = Σ(xₜ - x̄)² / Σ(xₜ - x̄)²
       = 1
```

**Вывод:** Любая величина идеально коррелирует сама с собой → корреляция = 1.

### PACF — ЧАСТНАЯ АВТОКОРРЕЛЯЦИОННАЯ ФУНКЦИЯ

**PACF(k)** показывает корреляцию между xₜ и xₜ₋ₖ, **ИСКЛЮЧАЯ** влияние промежуточных значений (xₜ₋₁, xₜ₋₂, ..., xₜ₋ₖ₊₁).

**Пример:**  
Допустим x₁ влияет на x₂, а x₂ влияет на x₃.  
Тогда x₁ **КОСВЕННО** связан с x₃ через x₂.
- **ACF(2)** покажет эту косвенную связь (x₁→x₂→x₃)
- **PACF(2)** покажет **ТОЛЬКО** прямую связь x₁→x₃ (убрав влияние x₂)

**В R:** `pacf(x)` строит график PACF

### МОДЕЛИ ARIMA

ARIMA — это модель, которая помогает прогнозировать значения временного ряда на основе его прошлых значений.

**Простыми словами:**
- Сначала она "убирает" тренды и сезонность (делает ряд более стабильным с помощью дифференцирования).
- Дальше использует две части:
  - **AR (AutoRegressive)** — учитывает, что текущее значение может зависеть от предыдущих (как будто "помнит" прошлое).
  - **MA (Moving Average)** — учитывает ошибки предсказаний в прошлом, чтобы скорректировать новые прогнозы.
- Параметры (p, d, q):
  - **p** — сколько прошлых значений брать в расчёт (AR)
  - **d** — сколько раз делать разности (дифференцировать)
  - **q** — сколько прошлых ошибок учитывать (MA)

**Итог:** ARIMA автоматически объединяет эти методы, чтобы лучше понять структуру ряда и предсказывать будущее.

---

### ДЕТАЛЬНОЕ ОБЪЯСНЕНИЕ ПАРАМЕТРОВ ARIMA

#### ПАРАМЕТР d (Differential — Дифференцирование)

**Что это:** Сколько раз нужно продифференцировать ряд, чтобы сделать его стационарным.

**Значения:**
- **d = 0** — ряд уже стационарный, дифференцирование не нужно
- **d = 1** — одно дифференцирование (xₜ - xₜ₋₁)
- **d = 2** — двойное дифференцирование (разность разностей)

**Как определить:**
- Если ряд имеет тренд → d = 1 (или больше)
- Если после одного diff ряд стационарный → d = 1 достаточно
- Если после одного diff всё ещё есть тренд → d = 2

**Что происходит в коде:**
```r
# d = 0: работаем с исходными данными
model_d0 <- arima(log_jj, order = c(1, 0, 1))

# d = 1: один раз берём diff()
model_d1 <- arima(log_jj, order = c(1, 1, 1))
# Внутри R делает: diff(log_jj) и применяет ARMA(1,1) к результату

# d = 2: два раза берём diff()
model_d2 <- arima(log_jj, order = c(1, 2, 1))
# Внутри R делает: diff(diff(log_jj))
```

**Зачем нужно:**
- Убирает тренд из ряда
- Делает ряд стационарным (условие для ARIMA)
- Без правильного d модель не будет работать!

**Риски:**
- d = 0 при наличии тренда → модель плохая (переоценит корреляции)
- d слишком большое → передифференцирование (потеря информации)

---

#### ПАРАМЕТР p (AR — AutoRegressive)

**Что это:** Порядок авторегрессии — сколько предыдущих ЗНАЧЕНИЙ ряда влияет на текущее.

**Формула AR(p):**
```
xₜ = φ₁×xₜ₋₁ + φ₂×xₜ₋₂ + ... + φₚ×xₜ₋ₚ + εₜ
```

**Значения:**
- **p = 0** — нет AR компоненты (не используем прошлые значения)
- **p = 1** — текущее значение зависит только от предыдущего: xₜ = φ₁×xₜ₋₁ + εₜ
- **p = 2** — зависит от двух предыдущих: xₜ = φ₁×xₜ₋₁ + φ₂×xₜ₋₂ + εₜ
- **p = 3, 4, ...** — зависит от большего числа предыдущих значений

**Как определить по ACF/PACF:**
- **PACF резко обрывается после лага p** → это AR(p)
- Пример: PACF имеет 2 значимых пика → p = 2

**Что происходит при разных p:**

```r
# p = 0: нет AR компоненты
model_p0 <- arima(log_jj, order = c(0, 1, 1))
# Модель: только MA(1) + дифференцирование

# p = 1: AR(1) — текущее зависит от одного предыдущего
model_p1 <- arima(log_jj, order = c(1, 1, 1))
# Модель: AR(1) + MA(1) + дифференцирование

# p = 2: AR(2) — текущее зависит от двух предыдущих
model_p2 <- arima(log_jj, order = c(2, 1, 1))
# Модель: AR(2) + MA(1) + дифференцирование
```

**Зачем нужно:**
- Учитывает "память" ряда — как прошлые значения влияют на текущее
- Чем больше p, тем больше "долгая память" (влияние более далёких значений)

**Когда использовать:**
- Если PACF показывает значимые пики → добавляем p
- Если ряд имеет "инерцию" (следует за прошлыми значениями) → нужен AR

**Риски:**
- p слишком большое → переобучение, модель усложняется
- p = 0 когда нужен → модель не учитывает важную информацию

---

#### ПАРАМЕТР q (MA — Moving Average)

**Что это:** Порядок скользящего среднего — сколько предыдущих ОШИБОК влияет на текущее значение.

**Формула MA(q):**
```
xₜ = εₜ + θ₁×εₜ₋₁ + θ₂×εₜ₋₂ + ... + θₚ×εₜ₋ₚ
```

где εₜ — это ошибки (шум) в момент времени t.

**Значения:**
- **q = 0** — нет MA компоненты (не учитываем прошлые ошибки)
- **q = 1** — текущее значение зависит от одной предыдущей ошибки: xₜ = εₜ + θ₁×εₜ₋₁
- **q = 2** — зависит от двух предыдущих ошибок: xₜ = εₜ + θ₁×εₜ₋₁ + θ₂×εₜ₋₂

**Как определить по ACF/PACF:**
- **ACF резко обрывается после лага q** → это MA(q)
- Пример: ACF имеет 1 значимый пик → q = 1

**Что происходит при разных q:**

```r
# q = 0: нет MA компоненты
model_q0 <- arima(log_jj, order = c(1, 1, 0))
# Модель: только AR(1) + дифференцирование

# q = 1: MA(1) — учитываем одну предыдущую ошибку
model_q1 <- arima(log_jj, order = c(0, 1, 1))
# Модель: MA(1) + дифференцирование

# q = 2: MA(2) — учитываем две предыдущие ошибки
model_q2 <- arima(log_jj, order = c(0, 1, 2))
# Модель: MA(2) + дифференцирование
```

**Зачем нужно:**
- Учитывает "шоки" и краткосрочные отклонения
- Помогает модели быстро адаптироваться к изменениям
- MA компонента часто лучше работает для краткосрочных зависимостей

**Когда использовать:**
- Если ACF показывает значимые пики → добавляем q
- Если ряд имеет "шумные" колебания → нужен MA

**Разница AR vs MA:**
- **AR(p):** текущее зависит от прошлых ЗНАЧЕНИЙ ряда
- **MA(q):** текущее зависит от прошлых ОШИБОК

---

#### СЕЗОННЫЕ ПАРАМЕТРЫ: P, D, Q

Для сезонных рядов (как квартальные данные) нужна сезонная компонента.

**ARIMA(p,d,q) × (P,D,Q)[s]**

**Параметры сезонной части:**

**P** — сезонный порядок AR
- P = 0: нет сезонной AR
- P = 1: текущий квартал зависит от того же квартала год назад

**D** — сезонное дифференцирование
- D = 0: нет сезонного diff
- D = 1: берём разность с лагом s (например, Q4 этого года - Q4 прошлого года)

**Q** — сезонный порядок MA
- Q = 0: нет сезонной MA
- Q = 1: учитываем сезонные ошибки прошлого года

**s** — период сезонности
- Для квартальных данных: s = 4
- Для месячных данных: s = 12

**Пример:**
```r
# ARIMA(0,1,1) × (0,1,1)[4]
# Несезонная часть: p=0, d=1, q=1
# Сезонная часть: P=0, D=1, Q=1, период=4
model <- arima(log_jj, 
               order = c(0, 1, 1), 
               seasonal = list(order = c(0, 1, 1), period = 4))
```

**Что означает сезонное дифференцирование (D=1):**
- Берём разность: xₜ - xₜ₋₄ (текущий квартал - тот же квартал год назад)
- Убирает сезонный тренд
- Нужно когда есть устойчивая сезонность

---

**Как читать:** ARIMA(1, 1, 1) означает:
1. Берём `diff(x)` — одно дифференцирование (d=1)
2. К результату применяем ARMA(1,1) — AR(1) + MA(1)

### AR(p) — АВТОРЕГРЕССИЯ

**Идея:** текущее значение зависит от p предыдущих значений.

**Формулы:**
- **AR(1):** xₜ = φ₁×xₜ₋₁ + εₜ
- **AR(2):** xₜ = φ₁×xₜ₋₁ + φ₂×xₜ₋₂ + εₜ
- **AR(p):** xₜ = φ₁×xₜ₋₁ + φ₂×xₜ₋₂ + ... + φₚ×xₜ₋ₚ + εₜ

где:
- εₜ — случайный шум (белый шум)
- φ₁, φ₂, ... — коэффициенты модели

**Как распознать AR(p) по графикам:**
- **ACF:** медленно затухает (экспоненциально или синусоидально)
- **PACF:** **РЕЗКО** обрывается после лага p (значимы только первые p значений)

**Паттерн из задания 4.11:**
- AR(1): PACF имеет 1 значимый пик
- AR(2): PACF имеет 2 значимых пика
- AR(3): PACF имеет 3 значимых пика
- AR(4): PACF имеет 4 значимых пика

**ЗАКОНОМЕРНОСТЬ:** число значимых пиков PACF = порядок p модели AR

### MA(q) — СКОЛЬЗЯЩЕЕ СРЕДНЕЕ

**Идея:** текущее значение зависит от q предыдущих **ОШИБОК**.

**Формулы:**
- **MA(1):** xₜ = εₜ + θ₁×εₜ₋₁
- **MA(2):** xₜ = εₜ + θ₁×εₜ₋₁ + θ₂×εₜ₋₂
- **MA(q):** xₜ = εₜ + θ₁×εₜ₋₁ + ... + θₚ×εₜ₋ₚ

где:
- εₜ — текущая ошибка (белый шум)
- θ₁, θ₂, ... — коэффициенты модели

**Как распознать MA(q) по графикам:**
- **ACF:** **РЕЗКО** обрывается после лага q
- **PACF:** медленно затухает

**Паттерн из задания 4.12:**
- MA(1): ACF имеет 1 значимый пик
- MA(2): ACF имеет 2 значимых пика
- MA(3): ACF имеет 3 значимых пика
- MA(4): ACF имеет 4 значимых пика

**ЗАКОНОМЕРНОСТЬ:** число значимых пиков ACF = порядок q модели MA

Это **ПРОТИВОПОЛОЖНО** AR моделям!

### ARMA(p,q) — КОМБИНАЦИЯ

**ARMA(p,q)** сочетает авторегрессию и скользящее среднее:

**xₜ = φ₁×xₜ₋₁ + ... + φₚ×xₜ₋ₚ + εₜ + θ₁×εₜ₋₁ + ... + θₚ×εₜ₋ₚ**

**Как распознать:**
- Оба графика (ACF и PACF) затухают
- Подбираем p и q по AIC (информационный критерий)

### СЕЗОННАЯ ARIMA — SARIMA

**Обозначение:** ARIMA(p,d,q) × (P,D,Q)[s]

**Где:**
- (p,d,q) — обычная ARIMA (несезонная часть)
- (P,D,Q)[s] — сезонная компонента с периодом s

**Для квартальных данных:** s = 4 (4 квартала в году)

**Пример:** ARIMA(0,1,1) × (0,1,1)[4] означает:
- Обычная часть: d=1 (одно дифференцирование), q=1 (MA(1))
- Сезонная часть: D=1 (сезонное дифференцирование), Q=1 (сезонная MA(1))

**Как распознать:**
- Пики на лагах 4, 8, 12, ... (кратные периоду s)
- Нужно добавить сезонную компоненту!

### AIC — ИНФОРМАЦИОННЫЙ КРИТЕРИЙ АКАИКЕ

```
AIC = 2k - 2ln(L)
```

где:
- **k** — число параметров модели
- **L** — правдоподобие (likelihood) — насколько хорошо модель объясняет данные

**Чем МЕНЬШЕ AIC, тем ЛУЧШЕ модель!**

**Как работает:**  
AIC штрафует за сложность: добавление лишних параметров увеличивает k, что увеличивает AIC. Модель должна быть:
- Достаточно простой (не переобучаться)
- Но хорошо объяснять данные (высокое L)

**Пример сравнения моделей:**
- Модель 1: AIC = -282.53 ← лучше!
- Модель 2: AIC = -277.80
- Модель 3: AIC = -280.55
- Модель 4: AIC = -280.91

Выбираем модель с минимальным AIC!

### ПОЧЕМУ ln И log₁₀ ДАЮТ ОДИНАКОВЫЙ РЕЗУЛЬТАТ? (Задание 4.9)

**log₁₀(x) = ln(x) / ln(10) ≈ ln(x) / 2.303**

То есть **log₁₀(x) = k × ln(x)**, где k = 1/ln(10) ≈ 0.434

**Когда мы берём РАЗНОСТЬ:**
```
log₁₀(xₜ) - log₁₀(xₜ₋₁) = k×ln(xₜ) - k×ln(xₜ₋₁) = k × [ln(xₜ) - ln(xₜ₋₁)]
```

Это просто **МАСШТАБИРОВАНИЕ** на константу k!

Для анализа временных рядов важна **СТРУКТУРА** корреляций и паттернов, а не конкретные числовые значения. Умножение на константу **НЕ** меняет:
- Форму ACF и PACF
- Выбор модели ARIMA
- Качество предсказаний (после обратного преобразования)

**Вывод:** можно использовать любой логарифм, результат будет **ЭКВИВАЛЕНТЕН**!

---

## ЧАСТЬ 2: РАЗБОР КОДА

### ЗАГРУЗКА ДАННЫХ

```r
jj <- scan("jj.dat")
# scan() читает числа из файла в вектор

jj_ts <- ts(jj, start = c(1960, 1), frequency = 4)
# ts() создаёт объект временного ряда
# start = c(1960, 1) — начало: 1960 год, 1-й квартал
# frequency = 4 — 4 наблюдения в год (квартальные данные)
```

### ПОСТРОЕНИЕ ГРАФИКОВ

```r
par(mfrow = c(2, 1))
# Разбивает окно на 2 строки и 1 столбец для нескольких графиков

plot(jj_ts, ...)
# Строит график временного ряда
```

### ДИФФЕРЕНЦИРОВАНИЕ

```r
diff_jj <- diff(jj_ts)
# diff() вычисляет xₜ - xₜ₋₁ для всех t > 1
# Было 84 значения → стало 83 (первое значение теряется)
```

### ЛОГАРИФМИРОВАНИЕ

```r
log_jj <- log10(jj_ts)
# Поэлементный логарифм по основанию 10

diff_log_jj <- diff(log_jj)
# Разность логарифмов = log(xₜ/xₜ₋₁)
```

### ACF И PACF

```r
acf(diff_log_jj, main = "...", lag.max = 20)
pacf(diff_log_jj, main = "...", lag.max = 20)
# lag.max — максимальный лаг для отображения
# Пунктирные линии на графике — границы значимости
# Если столбик выходит за пунктир — корреляция значима!
```

### ПОДГОНКА ARIMA

```r
model1 <- arima(log_jj, order = c(0, 1, 1), 
                seasonal = list(order = c(0, 1, 1), period = 4))
# order = c(p, d, q) — параметры ARIMA
# seasonal = list(order = c(P, D, Q), period = s) — сезонная часть

AIC(model1)
# Возвращает значение AIC для сравнения моделей
```

### СИМУЛЯЦИЯ

```r
arima.sim(n = 10000, list(ar = c(0.9, -0.5, 0.2, -0.3)))
# n — количество точек
# list(ar = ...) — коэффициенты AR модели
# list(ma = ...) — коэффициенты MA модели
```

---

## ЧАСТЬ 2.5: ЭКСПЕРИМЕНТЫ С ПАРАМЕТРАМИ

В коде проводятся 8 экспериментов для понимания влияния каждого параметра.

### ЭКСПЕРИМЕНТ 1: Влияние параметра d (дифференцирование)

**Цель:** Понять, нужно ли дифференцирование и как оно влияет на модель.

**Код:**
```r
model_d0 <- arima(log_jj, order = c(1, 0, 1), seasonal = list(order = c(0, 1, 1), period = 4))
model_d1 <- arima(log_jj, order = c(1, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
```

**Результаты:**
- ARIMA(1,0,1) с d=0: AIC = -283.97
- ARIMA(1,1,1) с d=1: AIC = -280.55

**Интересное наблюдение:**
- d=0 даёт лучший AIC! Но это обманчиво.
- Ряд log_jj уже логарифмирован, но всё ещё имеет тренд
- d=0 может работать на логарифмированных данных, но НЕ на исходных

**Вывод:**
- Для исходных данных (jj_ts) обязательно нужен d=1
- После логарифмирования тренд может стать более линейным, но всё ещё присутствует
- **Практический смысл:** обычно d=1 необходимо для рядов с трендом

---

### ЭКСПЕРИМЕНТ 2: Влияние параметра p (AR компонента)

**Цель:** Понять, как изменение p влияет на качество модели.

**Код:**
```r
for(p in 0:3) {
  model <- arima(log_jj, order = c(p, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
  cat("ARIMA(", p, ",1,1): AIC =", AIC(model), "\n")
}
```

**Результаты (реальные из эксперимента):**
- p = 0: AIC = -282.53 (лучше!)
- p = 1: AIC = -280.55 (хуже на 1.98)
- p = 2: AIC = -280.34 (ещё хуже)
- p = 3: AIC = -279.77 (ещё хуже)

**Интерпретация:**
- **p = 0 оптимально** для наших данных
- Увеличение p НЕ улучшает модель (AIC растёт)
- Это значит, что AR компонента не нужна или даже вредит
- **Вывод:** для этих данных достаточно MA компоненты, AR не требуется

**Почему так:**
- ACF показывает пик на лаге 1 → это MA сигнал, а не AR
- Добавление AR только усложняет модель без улучшения

---

### ЭКСПЕРИМЕНТ 3: Влияние параметра q (MA компонента)

**Цель:** Понять, какой порядок MA лучше.

**Код:**
```r
for(q in 0:3) {
  model <- arima(log_jj, order = c(0, 1, q), seasonal = list(order = c(0, 1, 1), period = 4))
  cat("ARIMA(0,1,", q, "): AIC =", AIC(model), "\n")
}
```

**Результаты (реальные из эксперимента):**
- q = 0: AIC = -258.13 (хуже, без MA компоненты, разница 24 единицы!)
- q = 1: AIC = -282.53 (лучше!)
- q = 2: AIC = -280.54 (хуже на 1.99)
- q = 3: AIC = -281.20 (хуже на 1.33)

**Интерпретация:**
- **q = 1 оптимально** для наших данных
- q = 0 плохо (нет MA компоненты, хотя она нужна)
- q > 1 не улучшает модель

**Вывод:**
- MA(1) компонента критически важна для этих данных
- Это подтверждается ACF графиком (пик на лаге 1)

---

### ЭКСПЕРИМЕНТ 4: Комбинации p и q (систематический перебор)

**Цель:** Найти оптимальную комбинацию p и q.

**Код:**
```r
for(p in 0:2) {
  for(q in 0:2) {
    model <- arima(log_jj, order = c(p, 1, q), seasonal = list(order = c(0, 1, 1), period = 4))
    # Записываем результаты
  }
}
```

**Результаты (реальная таблица из эксперимента):**

| p | q | AIC | Вывод |
|---|---|-----|-------|
| 0 | 0 | -258.13 | Плохо, нет AR и MA (разница 24 единицы!) |
| 0 | 1 | **-282.53** | **ЛУЧШАЯ!** |
| 0 | 2 | -280.54 | Хуже на 1.99 |
| 1 | 0 | -277.80 | AR без MA плохо работает |
| 1 | 1 | -280.55 | Хуже на 1.98 |
| 1 | 2 | -279.48 | Ещё хуже |
| 2 | 0 | -276.53 | Плохо |
| 2 | 1 | -280.34 | Хуже на 2.19 |
| 2 | 2 | -279.16 | Ещё хуже |

**Ключевые выводы:**
1. **ARIMA(0,1,1) — лучшая несезонная часть**
   - p = 0: AR не нужна
   - q = 1: MA(1) критически важна
   
2. **Добавление p ухудшает модель**
   - AR компонента не помогает для этих данных
   - Модель становится сложнее без улучшения качества
   
3. **q = 1 оптимально**
   - Увеличение q до 2+ не помогает
   - MA(1) достаточно для описания краткосрочных зависимостей

---

### ЭКСПЕРИМЕНТ 5: Влияние сезонных параметров

**Цель:** Понять, какие сезонные компоненты нужны.

**Код:**
```r
model_s1 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
model_s2 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(1, 1, 0), period = 4))
model_s3 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(1, 1, 1), period = 4))
model_s4 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 0), period = 4))
```

**Результаты (реальные):**
- (0,1,1): AIC = -282.53 ← лучшая!
- (1,1,0): AIC = -282.69 (очень близко, разница 0.16!)
- (1,1,1): AIC = -280.91 (хуже на 1.62)
- (0,1,0): AIC = -277.29 (плохая, нет сезонной MA)

**Интерпретация:**
- **Сезонная MA(1) (Q=1) критически важна**
  - Без неё модель сильно хуже
  - Это видно по пикам на лагах 4, 8, 12 в ACF
  
- **Сезонная AR (P) не нужна**
  - P=1 ухудшает модель (AIC выше)
  - Сезонность лучше описывается через сезонные ошибки, а не через сезонные значения
  
- **Сезонное дифференцирование (D=1) необходимо**
  - Убирает сезонный тренд
  - Без него сезонность не стационарна

**Вывод:** 
- Для квартальных данных оптимально: **(P=0, D=1, Q=1)**
- Классическая "airline model": ARIMA(0,1,1)×(0,1,1)[4]

---

### ЭКСПЕРИМЕНТ 6: Влияние сезонного дифференцирования D

**Цель:** Понять, нужно ли сезонное дифференцирование.

**Код:**
```r
model_season0 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 0, 1), period = 4))
model_season1 <- arima(log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))
```

**Результаты (реальные):**
- D=0 (без сезонного diff): AIC = -228.80 (очень плохо, разница 53.73!)
- D=1 (с сезонным diff): AIC = -282.53 (лучше!)

**Интерпретация:**
- **D=1 необходимо!** Сезонное дифференцирование критически важно
- Без него сезонность не стационарна, модель не может её правильно описать
- Сезонное diff убирает сезонный тренд (например, если каждый Q4 выше)

**Что делает сезонное diff:**
- Берёт разность: xₜ - xₜ₋₄ (текущий квартал - тот же квартал год назад)
- Убирает устойчивые сезонные паттерны
- Делает сезонность стационарной

---

### ЭКСПЕРИМЕНТ 7: Симуляции AR и MA моделей

**Цель:** Визуально понять, как p и q влияют на структуру данных.

**Код:**
```r
# AR модели
ar1 <- arima.sim(n = 10000, list(ar = c(0.9)))
ar2 <- arima.sim(n = 10000, list(ar = c(0.9, -0.5)))
# ...

# MA модели  
ma1 <- arima.sim(n = 10000, list(ma = c(-1.9)))
ma2 <- arima.sim(n = 10000, list(ma = c(-1.9, 1.7)))
# ...
```

**Наблюдения:**

**AR модели:**
- p = 1: PACF имеет 1 значимый пик
- p = 2: PACF имеет 2 значимых пика
- p = 3: PACF имеет 3 значимых пика
- p = 4: PACF имеет 4 значимых пика
- **Закономерность:** число значимых пиков PACF = p

**MA модели:**
- q = 1: ACF имеет 1 значимый пик
- q = 2: ACF имеет 2 значимых пика
- q = 3: ACF имеет 3 значимых пика
- q = 4: ACF имеет 4 значимых пика
- **Закономерность:** число значимых пиков ACF = q

**Вывод:**
- По симуляциям видно зеркальное поведение AR и MA
- Это помогает понять, какой параметр нужен для реальных данных

---

### ЭКСПЕРИМЕНТ 8: Сравнение разных значений d

**Цель:** Понять, можно ли использовать d=0 или d=2.

**Код:**
```r
mod_d0 <- arima(log_jj, order = c(2, 0, 2))  # может быть ошибка
mod_d1 <- arima(log_jj, order = c(2, 1, 2))
mod_d2 <- arima(log_jj, order = c(2, 2, 2))
```

**Результаты:**
- d = 0: на логарифмированных данных может дать хороший AIC (но не на исходных!)
- d = 1: стандартный выбор, AIC оптимальный
- d = 2: может работать, но обычно хуже (передифференцирование)

**Вывод:**
- **d = 1 оптимально** для наших данных
- d = 0 не работает (ряд нестационарный)
- d = 2 не нужно (передифференцирование ухудшает модель)

**Практический совет:**
- Всегда начинай с d = 1 для рядов с трендом
- Если после одного diff ряд стационарный → d = 1 достаточно
- Если после одного diff всё ещё есть тренд → попробуй d = 2 (редко нужно)

---

### ИТОГОВЫЕ ВЫВОДЫ ИЗ ЭКСПЕРИМЕНТОВ

1. **d = 1 критически важен**
   - Без дифференцирования модель не работает
   - d = 1 убирает тренд и делает ряд стационарным

2. **p = 0 оптимально**
   - AR компонента не улучшает модель
   - MA компонента важнее для этих данных

3. **q = 1 оптимально**
   - MA(1) критически важна
   - Увеличение q не помогает

4. **Сезонные параметры:**
   - D = 1 необходимо (сезонное дифференцирование)
   - Q = 1 оптимально (сезонная MA)
   - P = 0 (сезонная AR не нужна)

5. **Лучшая модель: ARIMA(0,1,1)×(0,1,1)[4]**
   - Минимальный AIC
   - Все параметры значимы
   - Классическая "airline model"

---

## ЧАСТЬ 3: РАЗБОР ВЫВОДА КОДА

### ВЫВОД scan("jj.dat")

```
"Read 84 items"
```

**Что это:**  
`scan()` читает числа из файла и выводит сообщение о количестве прочитанных значений. В файле jj.dat 84 значения (21 год × 4 квартала).

### ВЫВОД cat() — AIC МОДЕЛЕЙ

```
AIC моделей:
ARIMA(0,1,1)x(0,1,1)[4]: -282.5299 
ARIMA(1,1,0)x(0,1,1)[4]: -277.7962 
ARIMA(1,1,1)x(0,1,1)[4]: -280.5477 
ARIMA(0,1,1)x(1,1,1)[4]: -280.9088 
```

**Что это:**  
Функция `cat()` выводит текст и значения AIC для каждой модели. `AIC()` извлекает значение AIC из объекта модели.

**Откуда берутся числа:**
- AIC рассчитывается функцией `arima()` при подгонке модели
- Формула: AIC = 2k - 2ln(L), где k — число параметров, L — правдоподобие
- Меньшее значение = лучшая модель

**Интерпретация:**
- ARIMA(0,1,1)×(0,1,1)[4] имеет AIC = -282.53 — **НАИМЕНЬШЕЕ** значение
- Значит эта модель **ЛУЧШАЯ** из четырёх

### ВЫВОД print(best_model) — ДЕТАЛЬНАЯ ИНФОРМАЦИЯ О МОДЕЛИ

```
Call:
arima(x = log_jj, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = 4))

Coefficients:
          ma1     sma1
      -0.6809  -0.3146
s.e.   0.0982   0.1070

sigma^2 estimated as 0.001496:  log likelihood = 144.26,  aic = -282.53
```

**РАЗБОР ПО СТРОКАМ:**

1. **Строка "Call:"** — показывает какую команду использовали
   - `x = log_jj` — какие данные использовались (логарифм EPS)
   - `order = c(0, 1, 1)` — параметры несезонной части: p=0, d=1, q=1
   - `seasonal = list(order = c(0, 1, 1), period = 4)` — сезонная часть: P=0, D=1, Q=1, период=4

2. **Строка "Coefficients:"** — ОЦЕНЕННЫЕ КОЭФФИЦИЕНТЫ МОДЕЛИ
   
   - **ma1 = -0.6809** — коэффициент MA(1) компоненты (несезонной)  
     Что это: в модели MA(1) текущее значение зависит от предыдущей ошибки с весом -0.6809. Отрицательное значение означает отрицательную корреляцию.
   
   - **sma1 = -0.3146** — коэффициент сезонной MA(1) компоненты  
     Что это: влияние ошибки с лагом 4 (сезонный лаг) с весом -0.3146
   
   - **s.e. = standard error** (стандартная ошибка)
     - ma1 s.e. = 0.0982 — стандартная ошибка коэффициента ma1
     - sma1 s.e. = 0.1070 — стандартная ошибка коэффициента sma1
     
     Что это: мера точности оценки коэффициента. Чем меньше s.e., тем точнее оценка.
     
     **Проверка значимости:**  
     Если |коэффициент| / s.e. > 2, то коэффициент значим.
     - |-0.6809| / 0.0982 ≈ 6.93 > 2 → ma1 **ЗНАЧИМ**
     - |-0.3146| / 0.1070 ≈ 2.94 > 2 → sma1 **ЗНАЧИМ**

3. **Строка "sigma^2 estimated as ..."** — ОЦЕНКА ДИСПЕРСИИ ОШИБОК
   - **sigma^2 = 0.001496** — оценка дисперсии случайных ошибок (шума)
   
   Что это: средний квадрат разности между реальными значениями и предсказаниями модели. Чем меньше, тем лучше модель объясняет данные. В нашем случае 0.001496 — **ОЧЕНЬ** мало (хорошо!)

4. **Строка "log likelihood = ..."** — ЛОГАРИФМ ПРАВДОПОДОБИЯ
   - **log likelihood = 144.26** — натуральный логарифм функции правдоподобия
   
   Что это: мера того, насколько хорошо модель объясняет данные. Чем **БОЛЬШЕ** log likelihood, тем лучше модель. Используется для расчёта AIC.

5. **Строка "aic = ..."** — ИНФОРМАЦИОННЫЙ КРИТЕРИЙ АКАИКЕ
   - **aic = -282.53** — то же самое, что выводилось отдельно
   - Используется для сравнения моделей

### ВЫВОД tsdiag(best_model) — ДИАГНОСТИКА МОДЕЛИ

`tsdiag()` создаёт 3 графика:

1. **График 1: Остатки (Residuals)**
   - Показывает разности между реальными значениями и предсказаниями модели
   - Должны выглядеть как случайный шум (белый шум)
   - **НЕ** должно быть явных трендов или паттернов
   - Если есть тренд/паттерн — модель плохая

2. **График 2: ACF остатков (Autocorrelations)**
   - Показывает автокорреляцию остатков
   - Если модель хорошая, остатки **НЕ** должны коррелировать между собой
   - Все столбики должны быть **ВНУТРИ** пунктирных линий (не значимы)
   - Если есть значимые пики — модель пропустила какую-то зависимость

3. **График 3: p-values теста Льюнг-Бокса (Ljung-Box Test)**
   - Статистический тест на отсутствие автокорреляции в остатках
   - Нулевая гипотеза: остатки — белый шум (нет автокорреляции)
   - p-value > 0.05 → принимаем нулевую гипотезу (остатки хорошие)
   - p-value < 0.05 → отклоняем (остатки плохие, есть автокорреляция)
   - Все точки должны быть **ВЫШЕ** линии 0.05

---

## ЧАСТЬ 4: АНАЛИЗ РЕЗУЛЬТАТОВ

### ЗАДАНИЕ 4.8a: ГРАФИК ИСХОДНОГО РЯДА

На графике EPS vs время видно:

1. **Чёткий растущий ТРЕНД**
   - EPS увеличился с ~0.7 до ~16 за 21 год
   - Постоянный рост (не линейный, экспоненциальный)

2. **СЕЗОННОСТЬ**
   - Повторяющийся паттерн каждый год
   - Пики в определённых кварталах (обычно 4-й квартал выше)

3. **Увеличение АМПЛИТУДЫ колебаний со временем**
   - Когда EPS был ~1, колебания были ~0.3
   - Когда EPS стал ~15, колебания стали ~5
   - Это **ГЕТЕРОСКЕДАСТИЧНОСТЬ** (непостоянная дисперсия)

**Вывод:** ряд **НЕСТАЦИОНАРНЫЙ** (есть тренд, меняется дисперсия)

### ЗАДАНИЕ 4.8b: ПРОСТОЕ ДИФФЕРЕНЦИРОВАНИЕ

После `diff(xₜ)` — вычитания предыдущего значения:

1. **Тренд частично убран**
   - Ряд колеблется около нуля, а не растёт
   - Среднее примерно постоянно

2. **НО дисперсия всё ещё нестабильна**
   - В начале колебания ~0.3
   - В конце колебания ~5
   - Это плохо для ARIMA!

**Константная дисперсия важна** потому что:
- Модель предполагает одинаковый "разброс" ошибок во всех точках
- Если дисперсия разная, предсказания будут неточными
- Статистические тесты дадут неверные результаты

**Вывод:** простое дифференцирование **НЕ** достаточно!

### ЗАДАНИЕ 4.8c: ЛОГАРИФМИРОВАНИЕ + ДИФФЕРЕНЦИРОВАНИЕ

**log₁₀(EPS):**
- Тренд всё ещё есть, но стал более линейным
- Сезонность сохранилась
- Логарифм сам по себе не убирает тренд

**diff(log₁₀(EPS)):**
- Тренд **УБРАН** (через diff)
- Дисперсия стала **СТАБИЛЬНОЙ** (через log)
- Колебания примерно одинаковы
- Ряд выглядит стационарным!

**Вывод:** комбинация log + diff эффективно стационаризует ряд.  
Это и есть правильное преобразование для наших данных!

### ЗАДАНИЕ 4.8d: АНАЛИЗ ACF И PACF

На графиках ACF и PACF разности логарифмов видно:

**ACF:**
- Значимый пик на лаге 1 (высота ~0.6)
- Значимые пики на лагах 4, 8, 12 (кратные 4 — сезонность!)
- Медленное затухание сезонных пиков

**PACF:**
- Значимый пик на лаге 1
- Пики на сезонных лагах (4, 8, 12)

**Интерпретация:**
1. MA(1) компонента (пик на ACF при лаге 1)
2. Сезонная компонента с периодом 4 (пики на лагах 4, 8, 12)

**Предлагаемые модели:**
- ARIMA(0,1,1)×(0,1,1)[4] — MA(1) + сезонная MA(1) ← классическая "airline model"
- ARIMA(1,1,0)×(0,1,1)[4] — AR(1) + сезонная MA(1)
- ARIMA(1,1,1)×(0,1,1)[4] — смешанная ARMA(1,1) + сезонная MA(1)
- ARIMA(0,1,1)×(1,1,1)[4] — MA(1) + сезонная ARMA(1,1)

### ЗАДАНИЕ 4.8e: СРАВНЕНИЕ МОДЕЛЕЙ

По результатам AIC:
- ARIMA(0,1,1)×(0,1,1)[4]: **-282.53** ← **ЛУЧШАЯ** (минимальный AIC)
- ARIMA(0,1,1)×(1,1,1)[4]: -280.91
- ARIMA(1,1,1)×(0,1,1)[4]: -280.55
- ARIMA(1,1,0)×(0,1,1)[4]: -277.80

**Лучшая модель:** ARIMA(0,1,1)×(0,1,1)[4]  
Это классическая **"airline model"** для сезонных данных!

**Проверка диагностики (tsdiag):**
- Остатки похожи на белый шум (график 1)
- ACF остатков не имеет значимых пиков (график 2)
- p-values теста Льюнг-Бокса > 0.05 (график 3)
- Модель **ХОРОШАЯ**!

### ЗАДАНИЕ 4.11: ПАТТЕРНЫ AR(p)

- **AR(1):** PACF — 1 значимый пик, ACF — медленное экспоненциальное затухание
- **AR(2):** PACF — 2 значимых пика, ACF — затухание (возможно осцилляция)
- **AR(3):** PACF — 3 значимых пика, ACF — сложное затухание
- **AR(4):** PACF — 4 значимых пика, ACF — сложное затухание

**ЗАКОНОМЕРНОСТЬ:** число значимых пиков PACF = порядок p модели AR

### ЗАДАНИЕ 4.12: ПАТТЕРНЫ MA(q)

- **MA(1):** ACF — 1 значимый пик, PACF — медленное затухание
- **MA(2):** ACF — 2 значимых пика, PACF — затухание
- **MA(3):** ACF — 3 значимых пика, PACF — затухание
- **MA(4):** ACF — 4 значимых пика, PACF — затухание

**ЗАКОНОМЕРНОСТЬ:** число значимых пиков ACF = порядок q модели MA

Это **ЗЕРКАЛЬНО** относительно AR моделей!

---

## ЧАСТЬ 5: ОБЩИЙ АНАЛИЗ И ВЫВОДЫ

### ЧТО МЫ ДЕЛАЕМ И ЗАЧЕМ?

**Контекст задачи:**  
У нас есть данные Johnson & Johnson — квартальные доходы на акцию (EPS) за 21 год (1960-1980), всего 84 наблюдения.

**Цель:** построить модель, которая может:
1. Описать структуру временного ряда
2. Предсказать будущие значения EPS
3. Понять закономерности (тренд, сезонность)

### КЛЮЧЕВЫЕ ВЫВОДЫ ИЗ РЕЗУЛЬТАТОВ

1. **ИСХОДНЫЙ РЯД НЕСТАЦИОНАРНЫЙ**
   - Есть тренд (EPS растёт)
   - Есть сезонность (квартальные паттерны)
   - Непостоянная дисперсия (гетероскедастичность)
   - Нужно преобразовать!

2. **ПРЕОБРАЗОВАНИЕ log + diff ЭФФЕКТИВНО**
   - Тренд убран (через diff)
   - Дисперсия стабилизирована (через log)
   - Ряд стал стационарным
   - Можно строить ARIMA модель!

3. **ЛУЧШАЯ МОДЕЛЬ — ARIMA(0,1,1)×(0,1,1)[4]**
   - Минимальный AIC = -282.53
   - Классическая "airline model" для сезонных данных
   - Коэффициенты значимы (|coef|/s.e. > 2)
   - Диагностика хорошая (остатки — белый шум)

4. **СЕЗОННОСТЬ ВАЖНА**
   - Пики на лагах 4, 8, 12 в ACF/PACF
   - Без сезонной компоненты модель была бы хуже
   - Сезонное дифференцирование необходимо

5. **ПАТТЕРНЫ AR И MA РАЗЛИЧАЮТСЯ**
   - AR(p): PACF обрывается после лага p, ACF затухает
   - MA(q): ACF обрывается после лага q, PACF затухает
   - Это **ЗЕРКАЛЬНО**!

### ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ

1. **Всегда проверяйте стационарность:**
   - График исходного ряда
   - График разностей
   - ACF/PACF

2. **Преобразования по порядку:**
   - Если есть тренд → дифференцируем (diff)
   - Если дисперсия непостоянна → логарифмируем (log)
   - Если есть сезонность → сезонное дифференцирование

3. **Выбор модели:**
   - Смотрим на ACF/PACF
   - Предлагаем несколько моделей
   - Сравниваем по AIC (меньше = лучше)
   - Проверяем диагностику (tsdiag)

4. **Интерпретация коэффициентов:**
   - Проверяем значимость (|coef|/s.e. > 2)
   - Смотрим на знак (положительный/отрицательный)
   - Анализируем сезонные компоненты

5. **AIC для сравнения:**
   - Всегда сравниваем модели по AIC
   - Меньшее AIC = лучше
   - Но проверяем диагностику тоже!

---

## ЧАСТЬ 6: ШПАРГАЛКА

### КАК ВЫБРАТЬ МОДЕЛЬ ARIMA?

Смотрим на ACF и PACF стационарного ряда:

1. ACF резко обрывается после лага q, PACF затухает → **MA(q)**
2. PACF резко обрывается после лага p, ACF затухает → **AR(p)**
3. Оба затухают → **ARMA(p,q)**, подбираем по AIC
4. Есть пики на сезонных лагах (4, 8, 12...) → добавляем сезонную компоненту

**Если ряд нестационарный:**
- Есть тренд → дифференцируем (d = 1 или 2)
- Дисперсия меняется → логарифмируем
- Есть сезонный тренд → сезонное дифференцирование (D = 1)

### AR VS MA — КАК РАЗЛИЧИТЬ?

**AR(p):**
- PACF обрывается после лага p
- ACF затухает медленно

**MA(q):**
- ACF обрывается после лага q
- PACF затухает медленно

**ЗЕРКАЛЬНО!**

### ПРЕОБРАЗОВАНИЯ — КОГДА ЧТО?

- Тренд есть → `diff()` (дифференцирование)
- Дисперсия непостоянна → `log()` (логарифмирование)
- Сезонность есть → сезонное `diff()` + сезонная ARIMA

**Обычно:** log → diff → ARIMA

### AIC — КАК ИСПОЛЬЗОВАТЬ?

1. Подгоняем несколько моделей
2. Сравниваем AIC
3. Выбираем с минимальным AIC
4. **НО** проверяем диагностику тоже!

### ДИАГНОСТИКА МОДЕЛИ

`tsdiag()` показывает 3 графика:

1. Остатки — должны быть белым шумом (случайные)
2. ACF остатков — не должно быть значимых пиков
3. p-values Льюнг-Бокса — должны быть > 0.05

**Если всё ок → модель хорошая!**

---

## ПОЛЕЗНЫЕ КОМАНДЫ

| Команда | Описание |
|---------|----------|
| `scan("file.dat")` | Чтение чисел из файла |
| `ts(data, start=c(1960,1), frequency=4)` | Создание временного ряда |
| `diff(x)` | Дифференцирование |
| `log10(x)` или `log(x)` | Логарифмирование |
| `acf(x, lag.max=20)` | Автокорреляционная функция |
| `pacf(x, lag.max=20)` | Частная автокорреляционная функция |
| `arima(x, order=c(p,d,q), seasonal=list(order=c(P,D,Q), period=s))` | Подгонка ARIMA |
| `AIC(model)` | Информационный критерий Акаике |
| `print(model)` | Вывод информации о модели |
| `tsdiag(model)` | Диагностика модели |
| `arima.sim(n=10000, list(ar=c(...)))` | Симуляция AR модели |
| `arima.sim(n=10000, list(ma=c(...)))` | Симуляция MA модели |
| `plot_ly(...)` | Интерактивные графики (plotly) |

---

