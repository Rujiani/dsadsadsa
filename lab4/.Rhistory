cluster = as.factor(1:10)
)
df_plot <- data.frame(
state = rownames(cluster_data),
income = cluster_data[, "income"],
electricity = cluster_data[, "elec"],
cluster = as.factor(km_10$cluster)
)
p1 <- ggplot(df_plot, aes(x = income, y = electricity, color = cluster)) +
geom_point(size = 3) +
geom_point(data = centers_df, aes(x = income, y = electricity),
shape = 8, size = 5, stroke = 2) +
geom_text(aes(label = state), hjust = 0, vjust = -0.5, size = 2.5, show.legend = FALSE) +
labs(title = "K-means Clustering of US States (k=10)",
x = "Mean Household Income ($)",
y = "Mean Household Electricity Usage ($)",
color = "Cluster") +
theme_minimal() +
theme(legend.position = "right")
print(p1)
ggsave("kmeans_k10.png", p1, width = 12, height = 8, dpi = 150)
load("income_elec_state.Rdata")
cat("\n=== Data Summary ===\n")
print(head(income_elec_state))
print(summary(income_elec_state))
cat("Number of observations:", nrow(income_elec_state), "\n")
cluster_data <- as.matrix(income_elec_state[, c("income", "elec")])
cat("\n=== Task 4.1a: K-means Clustering with k=10 ===\n")
set.seed(123)
km_10 <- kmeans(cluster_data, centers = 10, nstart = 25)
cat("\nCluster sizes:\n")
print(km_10$size)
cat("\nCluster centers:\n")
print(km_10$centers)
par(mfrow = c(1, 1))
plot(cluster_data,
col = km_10$cluster,
pch = 19,
main = "K-means Clustering of US States (k=10)",
xlab = "Mean Household Income ($)",
ylab = "Mean Household Electricity Usage ($)")
points(km_10$centers, col = 1:10, pch = 8, cex = 2, lwd = 2)
legend("topright",
legend = paste("Cluster", 1:10),
col = 1:10,
pch = 19,
cex = 0.7)
text(cluster_data, labels = rownames(cluster_data), pos = 3, cex = 0.5)
df_plot <- data.frame(
state = rownames(cluster_data),
income = cluster_data[, "income"],
electricity = cluster_data[, "elec"],
cluster = as.factor(km_10$cluster)
)
centers_df <- data.frame(
income = km_10$centers[, "income"],
electricity = km_10$centers[, "elec"],
cluster = as.factor(1:10)
)
p1 <- ggplot(df_plot, aes(x = income, y = electricity, color = cluster)) +
geom_point(size = 3) +
geom_point(data = centers_df, aes(x = income, y = electricity),
shape = 8, size = 5, stroke = 2) +
geom_text(aes(label = state), hjust = 0, vjust = -0.5, size = 2.5, show.legend = FALSE) +
labs(title = "K-means Clustering of US States (k=10)",
x = "Mean Household Income ($)",
y = "Mean Household Electricity Usage ($)",
color = "Cluster") +
theme_minimal() +
theme(legend.position = "right")
print(p1)
ggsave("kmeans_k10.png", p1, width = 12, height = 8, dpi = 150)
cat("\n=== Task 4.1b: Understanding Clustering Variability ===\n")
cat("\nRunning k-means 5 times without fixed seed:\n")
for (i in 1:5) {
km_temp <- kmeans(cluster_data, centers = 10, nstart = 1)
cat(sprintf("Run %d - Total within-cluster SS: %.2f\n", i, km_temp$tot.withinss))
}
cat("\n")
cat("ANSWER: Each time you cluster the data, the following can change:\n")
cat("1. Cluster assignments - points may be assigned to different clusters\n")
cat("2. Centroid positions - cluster centers may vary\n")
cat("3. Within-cluster sum of squares\n")
cat("\nWHY: K-means uses random initial centroids. Different starting points\n")
cat("can lead to different local optima.\n")
cat("\nPREVENTION:\n")
cat("1. Use set.seed() before kmeans() for reproducibility\n")
cat("2. Use nstart parameter (e.g., nstart=25) to run multiple initializations\n")
cat("   and keep the best result\n")
cat("\n=== Task 4.1c: Determining Optimal k ===\n")
set.seed(123)
wss <- numeric(15)
for (i in 1:15) {
wss[i] <- sum(kmeans(cluster_data, centers = i, nstart = 25)$withinss)
}
par(mfrow = c(1, 1))
plot(1:15, wss, type = "b",
pch = 19,
xlab = "Number of Clusters (k)",
ylab = "Within-groups Sum of Squares",
main = "Elbow Method for Optimal k")
elbow_point <- 3
abline(v = elbow_point, lty = 2, col = "red")
text(elbow_point + 0.5, max(wss) * 0.8, paste("Suggested k =", elbow_point), col = "red")
sil_width <- numeric(14)
for (i in 2:15) {
km_temp <- kmeans(cluster_data, centers = i, nstart = 25)
sil <- silhouette(km_temp$cluster, dist(cluster_data))
sil_width[i-1] <- mean(sil[, 3])
}
plot(2:15, sil_width, type = "b",
pch = 19,
xlab = "Number of Clusters (k)",
ylab = "Average Silhouette Width",
main = "Silhouette Method for Optimal k")
optimal_k_sil <- which.max(sil_width) + 1
abline(v = optimal_k_sil, lty = 2, col = "blue")
text(optimal_k_sil + 0.5, max(sil_width) * 0.9, paste("Optimal k =", optimal_k_sil), col = "blue")
cat("\nElbow method suggests k around", elbow_point, "\n")
cat("Silhouette method suggests k =", optimal_k_sil, "\n")
cat("\nREASONING: A value of k=3 or k=4 appears reasonable because:\n")
cat("1. The elbow plot shows diminishing returns after k=3-4\n")
cat("2. States naturally group by income levels (low, medium, high)\n")
cat("3. Too many clusters (k=10) may overfit the data\n")
cat("\n=== Task 4.1d: Log10 Transformation Analysis ===\n")
cluster_data_log <- log10(cluster_data)
set.seed(123)
km_log_10 <- kmeans(cluster_data_log, centers = 10, nstart = 25)
par(mfrow = c(1, 2))
plot(cluster_data,
col = km_10$cluster,
pch = 19,
main = "Original Scale (k=10)",
xlab = "Income ($)",
ylab = "Electricity ($)")
points(km_10$centers, col = 1:10, pch = 8, cex = 2, lwd = 2)
plot(cluster_data_log,
col = km_log_10$cluster,
pch = 19,
main = "Log10 Scale (k=10)",
xlab = "Log10(Income)",
ylab = "Log10(Electricity)")
points(km_log_10$centers, col = 1:10, pch = 8, cex = 2, lwd = 2)
par(mfrow = c(1, 1))
cat("\nHOW CLUSTERING CHANGED:\n")
cat("1. Data points are more evenly spread on log scale\n")
cat("2. Clusters are more balanced in size\n")
cat("3. Outliers have less extreme influence\n")
cat("\nWHY:\n")
cat("1. Log transformation compresses high values and expands low values\n")
cat("2. Income data is typically right-skewed; log makes it more symmetric\n")
cat("3. On log scale, distances between observations are more proportional\n")
cat("4. The transformation equalizes the influence of both variables\n")
cat("\n=== Task 4.1e: Re-evaluating k with Log-Transformed Data ===\n")
set.seed(123)
wss_log <- numeric(15)
for (i in 1:15) {
wss_log[i] <- sum(kmeans(cluster_data_log, centers = i, nstart = 25)$withinss)
}
par(mfrow = c(1, 2))
plot(1:15, wss, type = "b", pch = 19,
xlab = "Number of Clusters", ylab = "WSS",
main = "Elbow: Original Scale")
plot(1:15, wss_log, type = "b", pch = 19,
xlab = "Number of Clusters", ylab = "WSS",
main = "Elbow: Log10 Scale")
par(mfrow = c(1, 1))
cat("\nANALYSIS:\n")
cat("With log-transformed data, the optimal k may differ because:\n")
cat("1. The spread of data is more uniform\n")
cat("2. Previously dominant income differences are normalized\n")
cat("3. A smaller k (e.g., k=3 or k=4) may be more appropriate\n")
cat("4. The elbow is often more pronounced on log scale\n")
cat("\n=== Task 4.1f: Outlier Detection and Removal ===\n")
cat("\nData summary to identify outliers:\n")
print(summary(cluster_data))
par(mfrow = c(1, 2))
boxplot(cluster_data[, "income"], main = "Income", ylab = "$")
boxplot(cluster_data[, "elec"], main = "Electricity", ylab = "$")
par(mfrow = c(1, 1))
income_q1 <- quantile(cluster_data[, "income"], 0.25)
income_q3 <- quantile(cluster_data[, "income"], 0.75)
income_iqr <- income_q3 - income_q1
income_lower <- income_q1 - 1.5 * income_iqr
income_upper <- income_q3 + 1.5 * income_iqr
outlier_idx <- which(cluster_data[, "income"] < income_lower |
cluster_data[, "income"] > income_upper)
if (length(outlier_idx) > 0) {
cat("\nIdentified outliers (by income):\n")
print(income_elec_state[outlier_idx, ])
} else {
cat("\nNo extreme outliers detected using IQR method.\n")
low_income_states <- rownames(cluster_data)[cluster_data[, "income"] < 30000]
if (length(low_income_states) > 0) {
cat("Potential outlier due to notably low income:\n")
print(income_elec_state[income_elec_state$state %in% low_income_states, ])
outlier_idx <- which(rownames(cluster_data) %in% low_income_states)
}
}
if (length(outlier_idx) > 0) {
cluster_data_no_outlier <- cluster_data[-outlier_idx, ]
cat("\nRe-clustering without outliers...\n")
set.seed(123)
wss_no_outlier <- numeric(15)
for (i in 1:15) {
wss_no_outlier[i] <- sum(kmeans(cluster_data_no_outlier, centers = i, nstart = 25)$withinss)
}
par(mfrow = c(1, 2))
plot(1:15, wss, type = "b", pch = 19,
xlab = "Number of Clusters", ylab = "WSS",
main = "With Outliers")
plot(1:15, wss_no_outlier, type = "b", pch = 19,
xlab = "Number of Clusters", ylab = "WSS",
main = "Without Outliers")
par(mfrow = c(1, 1))
cat("\nAfter removing outliers, optimal k may be smaller because:\n")
cat("1. Data is more homogeneous\n")
cat("2. Extreme values no longer force separate clusters\n")
cat("3. k=3 or k=4 is likely sufficient\n")
} else {
cluster_data_no_outlier <- cluster_data
}
cat("\n=== Task 4.1g: US Map Visualization ===\n")
optimal_k <- 4
set.seed(123)
km_final <- kmeans(cluster_data_no_outlier, centers = optimal_k, nstart = 25)
state_abbr_to_name <- c(
AL = "alabama", AK = "alaska", AZ = "arizona", AR = "arkansas", CA = "california",
CO = "colorado", CT = "connecticut", DE = "delaware", DC = "district of columbia", FL = "florida",
GA = "georgia", HI = "hawaii", ID = "idaho", IL = "illinois", IN = "indiana",
IA = "iowa", KS = "kansas", KY = "kentucky", LA = "louisiana", ME = "maine",
MD = "maryland", MA = "massachusetts", MI = "michigan", MN = "minnesota", MS = "mississippi",
MO = "missouri", MT = "montana", NE = "nebraska", NV = "nevada", NH = "new hampshire",
NJ = "new jersey", NM = "new mexico", NY = "new york", NC = "north carolina", ND = "north dakota",
OH = "ohio", OK = "oklahoma", OR = "oregon", PA = "pennsylvania", PR = "puerto rico",
RI = "rhode island", SC = "south carolina", SD = "south dakota", TN = "tennessee", TX = "texas",
UT = "utah", VT = "vermont", VA = "virginia", WA = "washington", WV = "west virginia",
WI = "wisconsin", WY = "wyoming"
)
cluster_assignments <- data.frame(
abbr = rownames(cluster_data_no_outlier),
cluster = as.factor(km_final$cluster),
stringsAsFactors = FALSE
)
cluster_assignments$state <- state_abbr_to_name[cluster_assignments$abbr]
us_states <- map_data("state")
us_states_clustered <- us_states %>%
left_join(cluster_assignments, by = c("region" = "state"))
p_map <- ggplot(us_states_clustered, aes(x = long, y = lat, group = group, fill = cluster)) +
geom_polygon(color = "white", linewidth = 0.3) +
coord_fixed(1.3) +
scale_fill_brewer(palette = "Set1", na.value = "grey90") +
labs(title = paste("US States Clustered by Income & Electricity (k=", optimal_k, ")", sep = ""),
subtitle = "48 contiguous states + DC",
fill = "Cluster") +
theme_void() +
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
plot.subtitle = element_text(hjust = 0.5, size = 10),
legend.position = "bottom"
)
if (!require("maps")) install.packages("maps", repos = "https://cloud.r-project.org")
install.packages("maps", repos = "https://cloud.r-project.org")
install.packages("maps", repos = "https://cloud.r-project.org")
install.packages("maps", repos = "https://cloud.r-project.org")
if (!require("dplyr")) install.packages("dplyr", repos = "https://cloud.r-project.org")
if (!require("cluster")) install.packages("cluster", repos = "https://cloud.r-project.org")
if (!require("factoextra")) install.packages("factoextra", repos = "https://cloud.r-project.org")
library(RODBC)
library(ggplot2)
library(maps)
library(dplyr)
library(cluster)
library(factoextra)
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
map_order <- c('AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL',
'GA', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME',
'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV',
'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR',
'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA',
'WA', 'WV', 'WI', 'WY')
cluster_vector <- km_final$cluster
names(cluster_vector) <- rownames(cluster_data_no_outlier)
map_color <- cluster_vector[map_order]
cat("\nCluster assignments for map:\n")
print(data.frame(state = map_order, cluster = map_color))
tryCatch({
par(mar = c(1, 1, 3, 1))
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
title(main = paste("US States Clustered by Income & Electricity (k=", optimal_k, ")", sep = ""))
legend("bottomleft",
legend = paste("Cluster", 1:optimal_k),
fill = 1:optimal_k,
cex = 0.8,
title = "Clusters",
bg = "white")
par(mar = c(5, 4, 4, 2) + 0.1)
}, error = function(e) {
cat("\nMap visualization failed:", e$message, "\n")
cat("Try running: install.packages('maps')\n")
cat("Showing table instead:\n")
cluster_table <- data.frame(
state = map_order,
cluster = map_color
)
print(cluster_table[order(cluster_table$cluster), ])
})
cat("\nStates in each cluster:\n")
for (i in 1:optimal_k) {
states_in_cluster <- rownames(cluster_data_no_outlier)[km_final$cluster == i]
cat(sprintf("\nCluster %d (%d states):\n", i, length(states_in_cluster)))
cat(paste(states_in_cluster, collapse = ", "), "\n")
}
cat("\n=== Task 4.1b: Hierarchical Clustering ===\n")
d <- dist(cluster_data, method = "euclidean")
linkage_methods <- c("complete", "single", "average", "ward.D2")
par(mfrow = c(2, 2), mar = c(2, 4, 3, 1), oma = c(1, 1, 1, 1))
hc_list <- list()
for (method in linkage_methods) {
hc <- hclust(d, method = method)
hc_list[[method]] <- hc
plot(hc, main = paste("Hierarchical Clustering:", method),
xlab = "", sub = "", cex = 0.5, cex.main = 0.9)
rect.hclust(hc, k = 4, border = "red")
}
par(mfrow = c(1, 1), mar = c(5, 4, 4, 2) + 0.1, oma = c(0, 0, 0, 0))
cat("\nComparing linkage methods (k=4):\n\n")
for (method in linkage_methods) {
clusters <- cutree(hc_list[[method]], k = 4)
cat(sprintf("%s linkage - Cluster sizes: %s\n",
toupper(method),
paste(table(clusters), collapse = ", ")))
}
cat("\nDIFFERENCES OBSERVED:\n")
cat("1. COMPLETE linkage: Creates more balanced clusters, considers\n")
cat("   maximum distance between points in clusters\n")
cat("2. SINGLE linkage: Tends to create 'chaining' effect, one large\n")
cat("   cluster with outliers as singletons\n")
cat("3. AVERAGE linkage: Compromise between single and complete,\n")
cat("   uses average distance between all pairs\n")
cat("4. WARD.D2: Minimizes within-cluster variance, creates\n")
cat("   compact, spherical clusters\n")
cat("\nWard's method often produces results most similar to K-means.\n")
if (require(factoextra)) {
fviz_dend(hc_list[["ward.D2"]], k = 4,
cex = 0.5,
main = "Hierarchical Clustering (Ward's Method)",
xlab = "States",
ylab = "Height",
color_labels_by_k = TRUE,
rect = TRUE)
}
cat("\n=== Summary ===\n")
cat("\n1. K-MEANS CLUSTERING:\n")
cat("   - Partitions data into k clusters\n")
cat("   - Sensitive to initial centroid placement (use set.seed and nstart)\n")
cat("   - Works well when clusters are spherical and similar in size\n")
cat("   - Optimal k can be determined using elbow or silhouette methods\n")
cat("\n2. HIERARCHICAL CLUSTERING:\n")
cat("   - Creates a tree (dendrogram) of clusters\n")
cat("   - No need to specify k in advance\n")
cat("   - Different linkage methods produce different results\n")
cat("   - Ward's method often best for compact clusters\n")
cat("\n3. DATA TRANSFORMATION:\n")
cat("   - Log transformation normalizes skewed data\n")
cat("   - Helps when variables have different scales\n")
cat("   - May change optimal k value\n")
cat("\n4. OUTLIERS:\n")
cat("   - Can significantly affect clustering results\n")
cat("   - Consider removing or handling separately\n")
cat("   - Puerto Rico often appears as outlier due to lower income\n")
cat("\n=== Lab 4 Complete ===\n")
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
library(usmap)
tryCatch({
par(mar = c(1, 1, 3, 1))
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
title(main = paste("US States Clustered by Income & Electricity (k=", optimal_k, ")", sep = ""))
legend("bottomleft",
legend = paste("Cluster", 1:optimal_k),
fill = 1:optimal_k,
cex = 0.8,
title = "Clusters",
bg = "white")
par(mar = c(5, 4, 4, 2) + 0.1)
}, error = function(e) {
cat("\nMap visualization failed:", e$message, "\n")
cat("Try running: install.packages('maps')\n")
cat("Showing table instead:\n")
cluster_table <- data.frame(
state = map_order,
cluster = map_color
)
print(cluster_table[order(cluster_table$cluster), ])
})
cat("\nStates in each cluster:\n")
for (i in 1:optimal_k) {
states_in_cluster <- rownames(cluster_data_no_outlier)[km_final$cluster == i]
cat(sprintf("\nCluster %d (%d states):\n", i, length(states_in_cluster)))
cat(paste(states_in_cluster, collapse = ", "), "\n")
}
cat("\n=== Task 4.1b: Hierarchical Clustering ===\n")
d <- dist(cluster_data, method = "euclidean")
linkage_methods <- c("complete", "single", "average", "ward.D2")
par(mfrow = c(2, 2), mar = c(2, 4, 3, 1), oma = c(1, 1, 1, 1))
hc_list <- list()
for (method in linkage_methods) {
hc <- hclust(d, method = method)
hc_list[[method]] <- hc
plot(hc, main = paste("Hierarchical Clustering:", method),
xlab = "", sub = "", cex = 0.5, cex.main = 0.9)
rect.hclust(hc, k = 4, border = "red")
}
par(mfrow = c(1, 1), mar = c(5, 4, 4, 2) + 0.1, oma = c(0, 0, 0, 0))
cat("\nComparing linkage methods (k=4):\n\n")
for (method in linkage_methods) {
clusters <- cutree(hc_list[[method]], k = 4)
cat(sprintf("%s linkage - Cluster sizes: %s\n",
toupper(method),
paste(table(clusters), collapse = ", ")))
}
cat("\nDIFFERENCES OBSERVED:\n")
cat("1. COMPLETE linkage: Creates more balanced clusters, considers\n")
cat("   maximum distance between points in clusters\n")
cat("2. SINGLE linkage: Tends to create 'chaining' effect, one large\n")
cat("   cluster with outliers as singletons\n")
cat("3. AVERAGE linkage: Compromise between single and complete,\n")
cat("   uses average distance between all pairs\n")
cat("4. WARD.D2: Minimizes within-cluster variance, creates\n")
cat("   compact, spherical clusters\n")
cat("\nWard's method often produces results most similar to K-means.\n")
if (require(factoextra)) {
fviz_dend(hc_list[["ward.D2"]], k = 4,
cex = 0.5,
main = "Hierarchical Clustering (Ward's Method)",
xlab = "States",
ylab = "Height",
color_labels_by_k = TRUE,
rect = TRUE)
}
cat("\n=== Summary ===\n")
cat("\n1. K-MEANS CLUSTERING:\n")
cat("   - Partitions data into k clusters\n")
cat("   - Sensitive to initial centroid placement (use set.seed and nstart)\n")
cat("   - Works well when clusters are spherical and similar in size\n")
cat("   - Optimal k can be determined using elbow or silhouette methods\n")
cat("\n2. HIERARCHICAL CLUSTERING:\n")
cat("   - Creates a tree (dendrogram) of clusters\n")
cat("   - No need to specify k in advance\n")
cat("   - Different linkage methods produce different results\n")
cat("   - Ward's method often best for compact clusters\n")
cat("\n3. DATA TRANSFORMATION:\n")
cat("   - Log transformation normalizes skewed data\n")
cat("   - Helps when variables have different scales\n")
cat("   - May change optimal k value\n")
cat("\n4. OUTLIERS:\n")
cat("   - Can significantly affect clustering results\n")
cat("   - Consider removing or handling separately\n")
cat("   - Puerto Rico often appears as outlier due to lower income\n")
cat("\n=== Lab 4 Complete ===\n")
tryCatch({
par(mar = c(1, 1, 3, 1))
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
title(main = paste("US States Clustered by Income & Electricity (k=", optimal_k, ")", sep = ""))
legend("bottomleft",
legend = paste("Cluster", 1:optimal_k),
fill = 1:optimal_k,
cex = 0.8,
title = "Clusters",
bg = "white")
par(mar = c(5, 4, 4, 2) + 0.1)
}, error = function(e) {
cat("\nMap visualization failed:", e$message, "\n")
cat("Try running: install.packages('maps')\n")
cat("Showing table instead:\n")
cluster_table <- data.frame(
state = map_order,
cluster = map_color
)
print(cluster_table[order(cluster_table$cluster), ])
})
print(cluster_table[order(cluster_table$cluster), ])
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
par(mar = c(1, 1, 3, 1))
map('state', col = map_color, fill = TRUE, resolution = 0, border = "black")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
source("~/studDir/DS_R/lab4/kmeans_lab4.R")
for (method in linkage_methods) {
clusters <- cutree(hc_list[[method]], k = 5)
print(sprintf("%s linkage - Cluster sizes: %s",
toupper(method),
paste(table(clusters), collapse = ", ")))
}
fviz_dend(hc_list[["ward.D2"]], k = 5,
cex = 0.5,
main = "Hierarchical Clustering (Ward's Method)",
xlab = "States",
ylab = "Height",
color_labels_by_k = TRUE,
rect = TRUE)
